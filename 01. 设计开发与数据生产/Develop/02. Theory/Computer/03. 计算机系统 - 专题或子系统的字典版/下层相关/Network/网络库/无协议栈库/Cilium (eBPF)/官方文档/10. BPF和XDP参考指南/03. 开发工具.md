# eBPF

# 目录

# 开发工具

本节讨论 BPF 周围的当前用户空间工具、内省工具和内核控制旋钮。

> !NOTE
>
> BPF 周围的工具和基础设施仍在快速发展，因此可能无法提供所有可用工具的完整情况。

## 开发环境

下面可以找到针对 Fedora 和 Ubuntu 设置 BPF 开发环境的分步指南。这将指导您构建、安装和测试开发内核以及构建和安装 iproute2。

手动构建 iproute2 和 Linux 内核的步骤通常是不必要的，因为默认情况下主要发行版已经发布了足够新的内核，但需要测试前沿版本或分别向  iproute2 和 Linux 内核贡献 BPF 补丁。同样，出于调试和自省的目的，构建 bpftool 是可选的，但建议这样做。

### Fedora

略

### Ubuntu

以下内容适用于 Ubuntu 17.04 或更高版本：

```bash
$ sudo apt-get install -y make gcc libssl-dev bc libelf-dev libcap-dev \
  clang gcc-multilib llvm libncurses5-dev git pkg-config libmnl-dev bison flex \
  graphviz
```

### OpenSUSE Tumbleweed

略

## 编译内核

Linux 内核新 BPF 功能的开发发生在 `net-next` git 树中，最新的 BPF 修复位于 `net` 树中。以下命令将通过 git 获取 `net-next` 树的内核源代码：

```bash
$ git clone git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net-next.git
```

如果 git 提交历史记录不感兴趣，那么 `--depth 1` 将通过仅将 git 历史记录截断到最近的提交来更快地克隆树。

如果您对 `net` 树感兴趣，可以从此 url 克隆它：

```bash
$ git clone git://git.kernel.org/pub/scm/linux/kernel/git/netdev/net.git
```

互联网上有几十个关于如何构建 Linux 内核的教程，一个很好的资源是 Kernel Newbies 网站 (https://kernelnewbies.org/KernelBuild)，可以使用上面提到的两个 git 树之一进行操作。

确保生成的 `.config` 文件包含以下用于运行 BPF 的 `CONFIG_*` 条目。 Cilium 也需要这些条目。

```bash
CONFIG_CGROUP_BPF=y
CONFIG_BPF=y
CONFIG_BPF_SYSCALL=y
CONFIG_NET_SCH_INGRESS=m
CONFIG_NET_CLS_BPF=m
CONFIG_NET_CLS_ACT=y
CONFIG_BPF_JIT=y
CONFIG_LWTUNNEL_BPF=y
CONFIG_HAVE_EBPF_JIT=y
CONFIG_BPF_EVENTS=y
CONFIG_TEST_BPF=m
```

某些条目无法通过 `make menuconfig` 进行调整。例如，如果给定架构确实带有 eBPF JIT，则会自动选择 `CONFIG_HAVE_EBPF_JIT` 。在这种特定情况下， `CONFIG_HAVE_EBPF_JIT` 是可选的，但强烈建议使用。没有 eBPF JIT 编译器的架构将需要回退到内核解释器，但代价是执行 BPF 指令的效率较低。

### 验证设置

启动到新编译的内核后，导航到 BPF 自测试套件以测试 BPF 功能（当前工作目录指向克隆的 git 树的根目录）：

```bash
$ cd tools/testing/selftests/bpf/
$ make
$ sudo ./test_verifier
```

验证程序测试打印出当前正在执行的所有检查。运行所有测试结束时的摘要将转储测试成功和失败的信息：

```bash
$ Summary: 847 PASSED, 0 SKIPPED, 0 FAILED
```

> [!NOTE]
>
> 对于内核版本 4.16+，BPF 自测试依赖于 LLVM 6.0+，这是由不再需要内联的 BPF 函数调用引起的。有关更多信息，请参阅  [BPF to BPF Calls](https://docs.cilium.io/en/stable/bpf/architecture/#bpf-to-bpf-calls) 部分或来自内核补丁的求职信邮件 (https://lwn.net/Articles/741773/)。如果不使用此新功能，则并非每个 BPF 程序都依赖于 LLVM 6.0+。如果您的发行版不提供 LLVM 6.0+，您可以按照 [LLVM](https://docs.cilium.io/en/stable/bpf/toolchain/#tooling-llvm) 部分中的说明进行编译。

为了运行所有 BPF 自测试，需要以下命令：

```bash
$ sudo make run_tests
```

### 编译 iproute2

与 `net` （仅修复）和 `net-next` （新功能）内核树类似，iproute2 git 树有两个分支，即 `master` 和 `net-next` 分支基于 `net` 树， `net-next` 分支基于 `net-next` 内核树。这是必要的，以便头文件的更改可以在 iproute2 树中同步。

为了克隆 iproute2 `master` 分支，可以使用以下命令：

```bash
$ git clone https://git.kernel.org/pub/scm/network/iproute2/iproute2.git
```

同样，要克隆到 iproute2 的上述 `net-next` 分支，请运行以下命令：

```bash
$ git clone -b net-next https://git.kernel.org/pub/scm/network/iproute2/iproute2.git
```

之后，继续构建和安装：

```bash
$ cd iproute2/
$ ./configure --prefix=/usr
TC schedulers
 ATM    no

libc has setns: yes
SELinux support: yes
ELF support: yes
libmnl support: no
Berkeley DB: no

docs: latex: no
 WARNING: no docs can be built from LaTeX files
 sgml2html: no
 WARNING: no HTML docs can be built from SGML
$ make
[...]
$ sudo make install
```

确保 `configure` 脚本显示 `ELF support: yes` ，以便 iproute2 可以处理来自 LLVM 的 BPF 后端的 ELF 文件。 libelf 已在之前的 Fedora 和 Ubuntu 的依赖项安装说明中列出。

### 编译 bpftool

bpftool 是 BPF 程序和映射的调试和内省的重要工具。它是内核树的一部分，可在 `tools/bpf/bpftool/` 下找到。

确保如前所述克隆了 `net` 或 `net-next` 内核树。为了构建和安装 bpftool，需要执行以下步骤：

```bash
$ cd <kernel-tree>/tools/bpf/bpftool/
$ make
Auto-detecting system features:
...                        libbfd: [ on  ]
...        disassembler-four-args: [ OFF ]

  CC       xlated_dumper.o
  CC       prog.o
  CC       common.o
  CC       cgroup.o
  CC       main.o
  CC       json_writer.o
  CC       cfg.o
  CC       map.o
  CC       jit_disasm.o
  CC       disasm.o
make[1]: Entering directory '/home/foo/trees/net/tools/lib/bpf'

Auto-detecting system features:
...                        libelf: [ on  ]
...                           bpf: [ on  ]

  CC       libbpf.o
  CC       bpf.o
  CC       nlattr.o
  LD       libbpf-in.o
  LINK     libbpf.a
make[1]: Leaving directory '/home/foo/trees/bpf/tools/lib/bpf'
  LINK     bpftool
$ sudo make install

```

## LLVM

### LLVM

LLVM 是目前唯一提供 BPF 后端的编译器套件。 gcc 目前不支持 BPF。

BPF 后端已合并到 LLVM 的 3.7 版本中。主要发行版在打包 LLVM 时默认启用 BPF 后端，因此在最新发行版上安装 clang 和 llvm 足以开始将 C 编译成 BPF 目标文件。

典型的工作流程是BPF程序用C语言编写，由LLVM编译成对象/ELF文件，由用户空间BPF ELF加载器（例如iproute2或其他）解析，并通过BPF系统调用推送到内核中。内核验证 BPF 指令并对它们进行  JIT，返回程序的新文件描述符，然后可以将其附加到子系统（例如网络）。如果支持，子系统可以进一步将 BPF 程序卸载到硬件（例如 NIC）。

对于 LLVM，可以通过以下方式检查 BPF 目标支持：

```bash
$ llc --version
LLVM (http://llvm.org/):
LLVM version 3.8.1
Optimized build.
Default target: x86_64-unknown-linux-gnu
Host CPU: skylake

Registered Targets:
  [...]
  bpf        - BPF (host endian)
  bpfeb      - BPF (big endian)
  bpfel      - BPF (little endian)
  [...]
```

默认情况下， `bpf`  目标使用其编译时CPU的字节序，这意味着如果CPU的字节序是小字节序，则程序也以小字节序格式表示，如果CPU的字节序是大字节序字节序，程序以大字节序表示。这也与 BPF 的运行时行为相匹配，BPF 是通用的，并使用其运行所在的 CPU 的字节序，以免对任何格式的架构造成不利影响。

对于交叉编译，引入了两个目标 `bpfeb` 和 `bpfel` ，因为 BPF 程序可以在以一种字节序运行的节点上编译（例如 x86 上的小字节序）并运行在另一种字节序格式的节点上（例如，arm 上的大字节序）。请注意，前端 (clang) 也需要以目标字节序运行。

在不适用混合字节序的情况下，使用 `bpf` 作为目标是首选方式。例如，由于 `x86_64` 上的编译会导致目标 `bpf` 和 `bpfel` 的输出相同，因为它们是小尾数，因此触发编译的脚本也没有具有字节序意识。

最小的独立 XDP 删除程序可能类似于以下示例 ( `xdp-example.c` )：

```bash
#include <linux/bpf.h>

#ifndef __section
# define __section(NAME)                  \
   __attribute__((section(NAME), used))
#endif

__section("prog")
int xdp_drop(struct xdp_md *ctx)
{
    return XDP_DROP;
}

char __license[] __section("license") = "GPL";
```

然后可以将其编译并加载到内核中，如下所示：

```bash
$ clang -O2 -Wall --target=bpf -c xdp-example.c -o xdp-example.o
# ip link set dev em1 xdp obj xdp-example.o
```

> [!NOTE]
>
> 如上所述将 XDP BPF 程序附加到网络设备需要 Linux 4.11 以及支持 XDP 的设备，或者 Linux 4.12 或更高版本。

对于生成的目标文件，LLVM (>= 3.9) 使用官方 BPF 机器值，即 `EM_BPF` （十进制： `247` / 十六进制： `0xf7` ）。在此示例中，程序已使用 `x86_64` 下的 `bpf` 目标进行编译，因此显示 `LSB` （与 `MSB` 相对）字节序：

```bash
$ file xdp-example.o
xdp-example.o: ELF 64-bit LSB relocatable, *unknown arch 0xf7* version 1 (SYSV), not stripped
```

`readelf -a xdp-example.o` 将转储有关 ELF 文件的更多信息，这有时对于内省生成的节头、重定位条目和符号表很有用。

在不太可能的情况下，需要从头开始编译 clang 和 LLVM，可以使用以下命令：

```bash
$ git clone https://github.com/llvm/llvm-project.git
$ cd llvm-project
$ mkdir build
$ cd build
$ cmake -DLLVM_ENABLE_PROJECTS=clang -DLLVM_TARGETS_TO_BUILD="BPF;X86" -DBUILD_SHARED_LIBS=OFF -DCMAKE_BUILD_TYPE=Release -DLLVM_BUILD_RUNTIME=OFF  -G "Unix Makefiles" ../llvm
$ make -j $(getconf _NPROCESSORS_ONLN)
$ ./bin/llc --version
LLVM (http://llvm.org/):
LLVM version x.y.zsvn
Optimized build.
Default target: x86_64-unknown-linux-gnu
Host CPU: skylake

Registered Targets:
  bpf    - BPF (host endian)
  bpfeb  - BPF (big endian)
  bpfel  - BPF (little endian)
  x86    - 32-bit X86: Pentium-Pro and above
  x86-64 - 64-bit X86: EM64T and AMD64

$ export PATH=$PWD/bin:$PATH   # add to ~/.bashrc
```

确保 `--version` 提及 `Optimized build.` ，否则当 LLVM 处于调试模式时，程序的编译时间将显着增加（例如增加 10 倍或更多）

为了调试，clang 可以生成汇编器输出，如下所示：

```bash
$ clang -O2 -S -Wall --target=bpf -c xdp-example.c -o xdp-example.S
$ cat xdp-example.S
    .text
    .section    prog,"ax",@progbits
    .globl      xdp_drop
    .p2align    3
xdp_drop:                             # @xdp_drop
# BB#0:
    r0 = 1
    exit

    .section    license,"aw",@progbits
    .globl    __license               # @__license
__license:
    .asciz    "GPL"
```

从 LLVM 6.0 版本开始，还支持汇编器解析器。您可以直接使用BPF汇编器进行编程，然后使用llvm-mc将其汇编成目标文件。例如，您可以使用以下命令将上面列出的 xdp-example.S 组装回目标文件：

```bash
$ llvm-mc -triple bpf -filetype=obj -o xdp-example.o xdp-example.S
```

此外，较新的 LLVM 版本（>= 4.0）还可以将 dwarf 格式的调试信息存储到目标文件中。这可以通过通常的工作流程添加 `-g` 进行编译来完成。

```bash
$ clang -O2 -g -Wall --target=bpf -c xdp-example.c -o xdp-example.o
$ llvm-objdump -S --no-show-raw-insn xdp-example.o

xdp-example.o:        file format ELF64-BPF

Disassembly of section prog:
xdp_drop:
; {
    0:        r0 = 1
; return XDP_DROP;
    1:        exit
```

然后， `llvm-objdump` 工具可以使用编译中使用的原始 C 代码来注释汇编器输出。本例中的简单示例不包含太多 C 代码，但是，显示为 `0:` 和 `1:` 的行号直接对应于内核的验证程序日志。

这意味着，如果 BPF 程序被验证者拒绝， `llvm-objdump` 可以帮助将指令关联回原始 C 代码，这对于分析非常有用。

```bash
$ ip link set dev em1 xdp obj xdp-example.o verb

Prog section 'prog' loaded (5)!
 - Type:         6
 - Instructions: 2 (0 over limit)
 - License:      GPL

Verifier analysis:

0: (b7) r0 = 1
1: (95) exit
processed 2 insns

```

从验证器分析中可以看出， `llvm-objdump` 输出转储与内核相同的 BPF 汇编代码。

省略 `--no-show-raw-insn` 选项也会将原始 `struct bpf_insn` 转储为程序集前面的十六进制：

```bash
$ llvm-objdump -S xdp-example.o

xdp-example.o:        file format ELF64-BPF

Disassembly of section prog:
xdp_drop:
; {
   0:       b7 00 00 00 01 00 00 00     r0 = 1
; return foo();
   1:       95 00 00 00 00 00 00 00     exit
```

对于 LLVM IR 调试，BPF 的编译过程可以分为两个步骤，生成一个二进制 LLVM IR 中间文件 `xdp-example.bc` ，稍后可以将其传递给 llc：

```bash
$ clang -O2 -Wall --target=bpf -emit-llvm -c xdp-example.c -o xdp-example.bc
$ llc xdp-example.bc -march=bpf -filetype=obj -o xdp-example.o
```

生成的 LLVM IR 还可以通过以下方式转储为人类可读的格式：

```bash
clang -O2 -Wall -emit-llvm -S -c xdp-example.c -o -
```

LLVM 能够将调试信息（例如程序中使用的数据类型的描述）附加到生成的 BPF 目标文件中。默认情况下，这是 DWARF 格式。

BPF 使用的一个高度简化的版本称为 BTF（BPF 类型格式）。生成的 DWARF 可以转换为 BTF，然后通过 BPF 对象加载器加载到内核中。然后，内核将验证 BTF 数据的正确性并跟踪 BTF 数据包含的数据类型。

然后，可以使用 BTF 数据中的键和值类型对 BPF  映射进行注释，以便稍后的映射转储会导出映射数据以及相关类型信息。这允许更好的自省、调试和价值漂亮的打印。请注意，BTF  数据是通用调试数据格式，因此可以加载任何 DWARF 到 BTF 转换的数据（例如，内核的 vmlinux DWARF 数据可以转换为 BTF  并加载）。后者对于未来的 BPF 跟踪特别有用。

为了从 DWARF 调试信息生成 BTF，需要 elfutils (>= 0.173)。如果该选项不可用，则需要在编译期间将 `-mattr=dwarfris` 选项添加到 `llc` 命令中：

```bash
$ llc -march=bpf -mattr=help |& grep dwarfris
  dwarfris - Disable MCAsmInfo DwarfUsesRelocationsAcrossSections.
  [...]
```

使用 `-mattr=dwarfris` 的原因是因为标志 `dwarfris` ( `dwarf relocation in section` ) 禁用了 DWARF 和 ELF 符号表之间的 DWARF 横截面重定位，因为 libdw 没有适当的 BPF重定位支持，因此像 `pahole` 这样的工具将无法正确地从对象中转储结构。

elfutils (>= 0.173) 实现了正确的 BPF 重定位支持，因此无需 `-mattr=dwarfris` 选项也可以实现相同的效果。从目标文件中转储结构可以通过 DWARF 或 BTF 信息来完成。 `pahole` 此时使用 LLVM 发出的 DWARF 信息，但是，未来的 `pahole` 版本可能依赖 BTF（如果可用）。

要将 DWARF 转换为 BTF，需要最新的 pahole 版本 (>= 1.12)。如果某个发行包中没有提供最新的 pahole 版本，也可以从其官方 git 存储库获取：

```bash
$ git clone https://git.kernel.org/pub/scm/devel/pahole/pahole.git
```

`pahole` 附带选项 `-J` 将 DWARF 从目标文件转换为 BTF。可以按如下方式探测 `pahole` 是否支持 BTF（请注意， `pahole` 也需要 `llvm-objcopy` 工具，因此还要检查它是否存在）：

```bash
$ pahole --help | grep BTF
-J, --btf_encode           Encode as BTF
```

生成调试信息还需要前端通过将 `-g` 传递到 `clang` 命令行来生成源代码级调试信息。请注意，无论是否使用 `llc` 的 `dwarfris` 选项，都需要 `-g` 。生成目标文件的完整示例：

```bash
$ clang -O2 -g -Wall --target=bpf -emit-llvm -c xdp-example.c -o xdp-example.bc
$ llc xdp-example.bc -march=bpf -mattr=dwarfris -filetype=obj -o xdp-example.o
```

或者，通过使用clang仅构建带有调试信息的BPF程序(同样，当具有适当的有用版本时，可以省略dwarfris标志):

```bash
$ clang --target=bpf -O2 -g -c -Xclang -target-feature -Xclang +dwarfris -c xdp-example.c -o xdp-example.o
```

编译成功后，可以使用 `pahole` 根据DWARF信息正确转储BPF程序的结构：

```bash
$ pahole xdp-example.o
struct xdp_md {
        __u32                      data;                 /*     0     4 */
        __u32                      data_end;             /*     4     4 */
        __u32                      data_meta;            /*     8     4 */

        /* size: 12, cachelines: 1, members: 3 */
        /* last cacheline: 12 bytes */
};
```

通过选项 `-J`  `pahole` 最终可以从DWARF生成BTF。在目标文件中，DWARF 数据仍将与新添加的 BTF 数据一起保留。完整的 `clang` 和 `pahole` 示例组合：

```bash
$ clang --target=bpf -O2 -Wall -g -c -Xclang -target-feature -Xclang +dwarfris -c xdp-example.c -o xdp-example.o
$ pahole -J xdp-example.o
```

通过 `readelf` 工具可以看到 `.BTF` 部分的存在：

```bash
$ readelf -a xdp-example.o
[...]
  [18] .BTF              PROGBITS         0000000000000000  00000671
[...]
```

BPF 加载器（例如 iproute2）将检测并加载 BTF 部分，以便 BPF 映射可以用类型信息进行注释。

LLVM 默认使用 BPF 基本指令集来生成代码，以确保生成的目标文件也可以加载较旧的内核，例如长期稳定的内核（例如 4.9+）。

然而，LLVM 在 BPF 后端有一个 `-mcpu` 选择器，以便选择不同版本的 BPF 指令集，即在 BPF 基本指令集之上的指令集扩展，以便生成更高效、更小的指令集。代码。

可用的 `-mcpu` 选项可以通过以下方式查询：

```bash
$ llc -march bpf -mcpu=help
Available CPUs for this target:

  generic - Select the generic processor.
  probe   - Select the probe processor.
  v1      - Select the v1 processor.
  v2      - Select the v2 processor.
[...]
```

`generic` 处理器是默认处理器，也是BPF的基本指令集 `v1` 。选项 `v1` 和 `v2` 通常在交叉编译 BPF 程序且加载程序的目标主机与编译程序的目标主机不同的环境中很有用（因此可用的 BPF 内核功能也可能有所不同）。

推荐的 `-mcpu` 选项也是 Cilium 内部使用的 `-mcpu=probe` ！这里，LLVM BPF 后端查询内核是否有 BPF 指令集扩展的可用性，当发现可用时，LLVM 将在适当的时候使用它们来编译 BPF 程序。

带有 llc 的 `-mcpu=probe` 的完整命令行示例：

```bash
$ clang -O2 -Wall --target=bpf -emit-llvm -c xdp-example.c -o xdp-example.bc
$ llc xdp-example.bc -march=bpf -mcpu=probe -filetype=obj -o xdp-example.o
```

一般来说，LLVM IR 生成是独立于体系结构的。然而，使用 `clang --target=bpf` 与保留 `--target=bpf` 并因此使用 clang 的默认目标（根据底层架构的不同，可能是 `x86_64` 、 < b3> 或其他。

引用内核的 `Documentation/bpf/bpf_devel_QA.txt` ：

- BPF 程序可以递归地包含具有文件范围内联汇编代码的头文件。默认目标可以很好地处理这个问题，而如果 bpf 后端汇编器不理解这些汇编代码，则 bpf 目标可能会失败，这在大多数情况下都是如此。
- 当不使用 -g 进行编译时，其他 elf 部分（例如 `.eh_frame` 和 `.rela.eh_frame` ）可能会出现在具有默认目标的目标文件中，但不会出现在 bpf 目标中。
- 默认目标可以将C switch 语句转换为switch 表查找和跳转操作。由于开关表被放置在全局只读部分，因此bpf程序将无法加载。 bpf 目标不支持切换表优化。 clang 选项 `-fno-jump-tables` 可用于禁用开关表生成。
- 对于 clang `--target=bpf` ，保证指针或 long / unsigned long 类型的宽度始终为 64 位，无论底层 clang 二进制文件或默认目标（或内核）是否为 32 位。但是，当使用本机 clang 目标时，它将根据底层架构的约定来编译这些类型，这意味着在 32 位架构、指针或  long/unsigned long 类型的情况下，例如在 BPF 上下文结构中，宽度为 32 位，而 BPF LLVM 后端仍以 64  位运行。

在跟踪映射 CPU 寄存器的内核 `struct pt_regs` 或 CPU 寄存器宽度很重要的其他内核结构的情况下，主要需要本机目标。在所有其他情况（例如网络）中，使用 `clang --target=bpf` 是首选。

此外，从 LLVM 7.0 版本开始，LLVM 开始支持 32 位子寄存器和 BPF ALU32 指令。添加了新的代码生成属性 `alu32` 。启用后，LLVM 将尽可能尝试使用 32 位子寄存器，通常是在对 32 位类型进行操作时。具有 32 位子寄存器的关联 ALU 指令将成为 ALU32 指令。例如，对于以下示例代码：

```bash
$ cat 32-bit-example.c
    void cal(unsigned int *a, unsigned int *b, unsigned int *c)
    {
      unsigned int sum = *a + *b;
      *c = sum;
    }
```

在默认代码生成时，汇编器将如下所示：

```bash
$ clang --target=bpf -emit-llvm -S 32-bit-example.c
$ llc -march=bpf 32-bit-example.ll
$ cat 32-bit-example.s
    cal:
      r1 = *(u32 *)(r1 + 0)
      r2 = *(u32 *)(r2 + 0)
      r2 += r1
      *(u32 *)(r3 + 0) = r2
      exit
```

使用64位寄存器，因此加法意味着64位加法。现在，如果您通过指定 `-mattr=+alu32` 启用新的 32 位子寄存器支持，则汇编器将如下所示：

```bash
$ llc -march=bpf -mattr=+alu32 32-bit-example.ll
$ cat 32-bit-example.s
    cal:
      w1 = *(u32 *)(r1 + 0)
      w2 = *(u32 *)(r2 + 0)
      w2 += w1
      *(u32 *)(r3 + 0) = w2
      exit
```

`w` 寄存器，即32位子寄存器，将用来代替64位 `r` 寄存器。

启用 32 位子寄存器可能有助于减少类型扩展指令序列。它还可以帮助用于 32 位架构的内核 eBPF JIT 编译器，其中寄存器对用于对 64 位  eBPF 寄存器进行建模，并且需要额外的指令来操作高 32 位。给定从 32 位子寄存器读取保证只从低 32 位读取，即使写入仍然需要清除高  32 位，如果 JIT 编译器已知一个寄存器的定义只有子寄存器读取，则设置指令目标的高 32 位可以被消除。

### BPF 模型的一些差异

与使用 C 进行的常规应用程序开发相比，为 BPF 编写 C 程序时需要注意一些陷阱。以下各项描述了 **BPF 模型的一些差异**：

#### 一切都需要内联，没有可用的函数调用（在旧的 LLVM 版本上）或共享库调用

共享库等不能与 BPF 一起使用。但是，BPF 程序中使用的公共库代码可以放入头文件中并包含在主程序中。例如，Cilium 大量使用它（参见 `bpf/lib/` ）。但是，这仍然允许包含头文件，例如来自内核或其他库的头文件，并重用它们的静态内联函数或宏/定义。

除非使用支持 BPF 到 BPF 函数调用的最新内核 (4.16+) 和 LLVM (6.0+)，否则 LLVM 需要将整个代码编译并内联到给定程序部分的 BPF 指令的平面序列中。在这种情况下，最佳实践是对每个库函数使用类似 `__inline` 的注释，如下所示。建议使用 `always_inline` ，因为编译器仍然可以决定取消内联仅注释为 `inline` 的大型函数。

如果发生后者，LLVM 将在 ELF 文件中生成一个重定位条目，而 BPF ELF 加载程序（例如 iproute2）无法解析该重定位条目，因此会产生错误，因为只有 BPF 映射才是加载程序可以处理的有效重定位条目。

```bash
#include <linux/bpf.h>

#ifndef __section
# define __section(NAME)                  \
   __attribute__((section(NAME), used))
#endif

#ifndef __inline
# define __inline                         \
   inline __attribute__((always_inline))
#endif

static __inline int foo(void)
{
    return XDP_DROP;
}

__section("prog")
int xdp_drop(struct xdp_md *ctx)
{
    return foo();
}

char __license[] __section("license") = "GPL";
```

#### 多个程序可以驻留在单个 C 文件的不同部分中

BPF 的 C 程序大量使用节注释。 C 文件通常分为 3 个或更多部分。 BPF ELF 加载器使用这些名称来提取和准备相关信息，以便通过 bpf 系统调用加载程序和映射。例如，iproute2 使用 `maps` 和 `license` 作为默认部分名称，分别查找创建地图所需的元数据和 BPF 程序的许可证。在程序创建时，后者也被推送到内核中，并启用一些仅在程序也持有 GPL 兼容许可证的情况下公开为 GPL 的辅助函数，例如 `bpf_ktime_get_ns()` 、 `bpf_probe_read()` 和其他。

其余部分名称特定于 BPF 程序代码，例如，以下代码已修改为包含两个程序部分 `ingress` 和 `egress` 。玩具示例代码演示了两者可以共享映射和公共静态内联帮助器，例如 `account_data()` 函数。

`xdp-example.c` 示例已修改为 `tc-example.c` 示例，可以使用 tc 加载并附加到网络设备的入口和出口挂钩。它将传输的字节记入一个名为 `acc_map` 的映射，该映射有两个映射槽，一个用于在入口钩子上计算流量，一个用于在出口钩子上计算流量。

```bash
#include <linux/bpf.h>
#include <linux/pkt_cls.h>
#include <stdint.h>
#include <iproute2/bpf_elf.h>

#ifndef __section
# define __section(NAME)                  \
   __attribute__((section(NAME), used))
#endif

#ifndef __inline
# define __inline                         \
   inline __attribute__((always_inline))
#endif

#ifndef lock_xadd
# define lock_xadd(ptr, val)              \
   ((void)__sync_fetch_and_add(ptr, val))
#endif

#ifndef BPF_FUNC
# define BPF_FUNC(NAME, ...)              \
   (*NAME)(__VA_ARGS__) = (void *)BPF_FUNC_##NAME
#endif

static void *BPF_FUNC(map_lookup_elem, void *map, const void *key);

struct bpf_elf_map acc_map __section("maps") = {
    .type           = BPF_MAP_TYPE_ARRAY,
    .size_key       = sizeof(uint32_t),
    .size_value     = sizeof(uint32_t),
    .pinning        = PIN_GLOBAL_NS,
    .max_elem       = 2,
};

static __inline int account_data(struct __sk_buff *skb, uint32_t dir)
{
    uint32_t *bytes;

    bytes = map_lookup_elem(&acc_map, &dir);
    if (bytes)
            lock_xadd(bytes, skb->len);

    return TC_ACT_OK;
}

__section("ingress")
int tc_ingress(struct __sk_buff *skb)
{
    return account_data(skb, 0);
}

__section("egress")
int tc_egress(struct __sk_buff *skb)
{
    return account_data(skb, 1);
}

char __license[] __section("license") = "GPL";
```

该示例还演示了开发程序时需要注意的其他一些事项。该代码包括内核头文件、标准 C 头文件和包含 `struct bpf_elf_map` 定义的 iproute2 特定头文件。 iproute2 有一个通用的 BPF ELF 加载器，因此 `struct bpf_elf_map` 的定义对于 XDP 和 tc 类型程序来说是相同的。

`struct bpf_elf_map` 条目定义了程序中的映射，并包含生成两个 BPF 程序使用的映射所需的所有相关信息（例如键/值大小等）。该结构必须放入 `maps` 部分，以便加载器可以找到它。可以有多个具有不同变量名称的此类映射声明，但所有声明都必须使用 `__section("maps")` 进行注释。

`struct bpf_elf_map` 特定于 iproute2。不同的 BPF ELF 加载器可以有不同的格式，例如内核源码树中主要由 `perf` 使用的 libbpf 就有不同的规范。 iproute2 保证 `struct bpf_elf_map` 的向后兼容性。 Cilium 遵循 iproute2 模型。

该示例还演示了如何将 BPF 辅助函数映射到 C 代码并使用。这里， `map_lookup_elem()` 是通过将此函数映射到 `BPF_FUNC_map_lookup_elem` 枚举值来定义的，该枚举值在 `uapi/linux/bpf.h` 中作为助手公开。当程序稍后加载到内核中时，验证程序会检查传递的参数是否属于预期类型，并将帮助程序调用重新指向真正的函数调用。此外， `map_lookup_elem()` 还演示了如何将映射传递给 BPF 辅助函数。这里， `maps` 部分中的 `&acc_map` 作为第一个参数传递给 `map_lookup_elem()` 。

由于定义的数组映射是全局的，因此记账需要使用原子操作，定义为 `lock_xadd()` 。 LLVM 将 `__sync_fetch_and_add()` 作为内置函数映射到 BPF 原子添加指令，即表示字大小的 `BPF_STX | BPF_XADD | BPF_W` 。

最后但并非最不重要的一点是， `struct bpf_elf_map` 告诉地图将被固定为 `PIN_GLOBAL_NS` 。这意味着 tc 会将映射作为节点固定到 BPF 伪文件系统中。默认情况下，对于给定的示例，它将固定到 `/sys/fs/bpf/tc/globals/acc_map` 。由于 `PIN_GLOBAL_NS` ，地图将放置在 `/sys/fs/bpf/tc/globals/` 下。 `globals` 充当跨对象文件的全局命名空间。如果示例使用 `PIN_OBJECT_NS` ，那么 tc 将创建一个目标文件本地目录。例如，具有 BPF 代码的不同 C 文件可以具有与上面相同的 `acc_map` 定义，并带有 `PIN_GLOBAL_NS` 固定。在这种情况下，映射将在源自各种目标文件的 BPF 程序之间共享。 `PIN_NONE` 意味着该映射不会作为节点放入 BPF 文件系统中，因此在 tc 退出后将无法从用户空间访问。这也意味着 tc 为每个程序创建两个单独的地图实例，因为它无法检索以前固定在该名称下的地图。上述路径中的 `acc_map` 部分是源代码中指定的地图名称。

因此，在加载 `ingress` 程序时，tc会发现BPF文件系统中不存在这样的映射，并创建一个新的映射。成功后，该映射也将被固定，这样当通过 tc 加载 `egress` 程序时，它会发现该映射已存在于 BPF 文件系统中，并将其重用于 `egress`

就像 tc 可以检索相同的映射一样，第三方应用程序也可以使用 bpf 系统调用中的 `BPF_OBJ_GET` 命令来创建指向相同映射实例的新文件描述符，然后可以将其用于查找/更新/删除地图元素。

代码可以通过 iproute2 编译并加载，如下所示：

```bash
$ clang -O2 -Wall --target=bpf -c tc-example.c -o tc-example.o

# tc qdisc add dev em1 clsact
# tc filter add dev em1 ingress bpf da obj tc-example.o sec ingress
# tc filter add dev em1 egress bpf da obj tc-example.o sec egress

# tc filter show dev em1 ingress
filter protocol all pref 49152 bpf
filter protocol all pref 49152 bpf handle 0x1 tc-example.o:[ingress] direct-action id 1 tag c5f7825e5dac396f

# tc filter show dev em1 egress
filter protocol all pref 49152 bpf
filter protocol all pref 49152 bpf handle 0x1 tc-example.o:[egress] direct-action id 2 tag b2fd5adc0f262714

# mount | grep bpf
sysfs on /sys/fs/bpf type sysfs (rw,nosuid,nodev,noexec,relatime,seclabel)
bpf on /sys/fs/bpf type bpf (rw,relatime,mode=0700)

# tree /sys/fs/bpf/
/sys/fs/bpf/
+-- ip -> /sys/fs/bpf/tc/
+-- tc
|   +-- globals
|       +-- acc_map
+-- xdp -> /sys/fs/bpf/tc/

4 directories, 1 file
```

一旦数据包通过 `em1` 设备，BPF 映射中的计数器就会增加。

#### 不允许使用全局变量

由于第 1 点中已经提到的原因，BPF 不能像普通 C 程序中那样具有全局变量。

然而，有一个解决方法，程序可以简单地使用 `BPF_MAP_TYPE_PERCPU_ARRAY` 类型的 BPF 映射，其中只有一个任意值大小的槽。这是可行的，因为在执行期间，BPF 程序保证永远不会被内核抢占，因此可以使用单个映射条目作为临时数据的暂存缓冲区，例如，以超出堆栈限制。这也适用于尾部调用，因为它在抢占方面具有相同的保证。

否则，为了在多个 BPF 程序运行之间保持状态，可以使用普通的 BPF 映射。

#### 不允许使用 const 字符串或数组

在 BPF C 程序中定义 `const` 字符串或其他数组不起作用，原因与第 1 节和第 3 节中指出的相同，即，将在 ELF 文件中生成重定位条目，该重定位条目将被拒绝由于不是加载器 ABI 的一部分（加载器也无法修复此类条目，因为它需要对已编译的 BPF 序列进行大量重写）。

将来，LLVM 可能会检测到这些情况并尽早向用户抛出错误。

诸如 `trace_printk()` 之类的辅助函数可以按如下方式解决：

```bash
static void BPF_FUNC(trace_printk, const char *fmt, int fmt_size, ...);

#ifndef printk
# define printk(fmt, ...)                                      \
    ({                                                         \
        char ____fmt[] = fmt;                                  \
        trace_printk(____fmt, sizeof(____fmt), ##__VA_ARGS__); \
    })
#endif
```

然后程序可以像 `printk("skb len:%u\n", skb->len);` 一样自然地使用宏。然后输出将被写入跟踪管道。 `tc exec bpf dbg` 可用于从那里检索消息。

使用 `trace_printk()` 辅助函数有一些缺点，因此不建议在生产中使用。每次调用辅助函数时，像 `"skb len:%u\n"` 这样的常量字符串都需要加载到 BPF 堆栈中，而且 BPF 辅助函数最多只能有 5 个参数。这仅留下了 3 个可用于转储的附加变量的空间。

因此，尽管有助于快速调试，但建议（对于网络程序）分别使用 `skb_event_output()` 或 `xdp_event_output()` 帮助器。它们允许将自定义结构从 BPF 程序传递到 perf 事件环缓冲区以及可选的数据包样本。例如，Cilium 的监视器利用这些帮助程序来实现调试框架、网络策略违规通知等。这些帮助程序通过映射每个 CPU `perf` 环形缓冲区的无锁内存传递数据，并且因此比 `trace_printk()` 快得多。

#### 使用 LLVM 内置函数 memset()/memcpy()/memmove()/memcmp()

由于 BPF 程序无法执行除 BPF 助手之外的任何函数调用，因此公共库代码需要实现为内联函数。此外，LLVM 还提供了一些内置函数，程序可以将其用于恒定大小（此处： `n` ），然后它们将始终被内联：

```bash
#ifndef memset
# define memset(dest, chr, n)   __builtin_memset((dest), (chr), (n))
#endif

#ifndef memcpy
# define memcpy(dest, src, n)   __builtin_memcpy((dest), (src), (n))
#endif

#ifndef memmove
# define memmove(dest, src, n)  __builtin_memmove((dest), (src), (n))
#endif
```

`memcmp()` 内置函数存在一些极端情况，由于后端的 LLVM 问题，内联没有发生，因此在问题解决之前不建议使用。

#### 目前还没有可用的循环

除了其他控制流图验证之外，内核中的 BPF 验证器还通过对所有可能的程序路径执行深度优先搜索来检查 BPF 程序是否不包含循环。目的是确保程序始终保证终止。

通过使用 `#pragma unroll` 指令，可以使用非常有限的循环形式来实现恒定的循环上限。编译为 BPF 的示例代码：

```bash
#pragma unroll
    for (i = 0; i < IPV6_MAX_HEADERS; i++) {
        switch (nh) {
        case NEXTHDR_NONE:
            return DROP_INVALID_EXTHDR;
        case NEXTHDR_FRAGMENT:
            return DROP_FRAG_NOSUPPORT;
        case NEXTHDR_HOP:
        case NEXTHDR_ROUTING:
        case NEXTHDR_AUTH:
        case NEXTHDR_DEST:
            if (skb_load_bytes(skb, l3_off + len, &opthdr, sizeof(opthdr)) < 0)
                return DROP_INVALID;

            nh = opthdr.nexthdr;
            if (nh == NEXTHDR_AUTH)
                len += ipv6_authlen(&opthdr);
            else
                len += ipv6_optlen(&opthdr);
            break;
        default:
            *nexthdr = nh;
            return len;
        }
    }
```

另一种可能性是通过再次调用同一程序并使用 `BPF_MAP_TYPE_PERCPU_ARRAY` 映射来获得本地暂存空间，从而使用尾部调用。虽然是动态的，但这种形式的循环仅限于最多 34 次迭代（初始程序，加上尾部调用的 33 次迭代）。

将来，BPF 可能会有一些本机但有限形式的实现循环。

#### 使用尾调用对程序进行分区

尾部调用提供了在运行时通过从一个 BPF 程序跳转到另一个 BPF 程序以原子方式改变程序行为的灵活性。为了选择下一个程序，尾部调用使用程序数组映射（ `BPF_MAP_TYPE_PROG_ARRAY` ），并将映射以及索引传递给要跳转到的下一个程序。执行跳转后不会返回到旧程序，并且如果给定映射索引处不存在程序，则继续执行原始程序。

例如，这可以用于实现解析器的各个阶段，其中可以在运行时使用新的解析功能来更新这些阶段。

另一个用例是事件通知，例如，Cilium 可以在运行时选择数据包丢失通知，其中 `skb_event_output()` 调用位于尾部调用的程序内。因此，在正常操作期间，除非将程序添加到相关映射索引，否则将始终执行失败路径，然后该程序准备元数据并向用户空间守护程序触发事件通知。

程序数组映射非常灵活，还可以对位于每个映射索引中的程序执行单独的操作。例如，附加到 XDP 或 tc 的根程序可以对程序数组映射的索引 0 执行初始尾部调用，执行流量采样，然后跳转到程序数组映射的索引  1，其中应用防火墙策略并且数据包在程序数组映射的索引 2  中丢弃或进一步处理，在那里它被破坏并再次从接口发送出去。当然，程序数组映射中的跳转可以是任意的。当达到最大尾调用限制时，内核最终将执行失败路径。

使用尾部调用的最小示例摘录：

```bash
[...]

#ifndef __stringify
# define __stringify(X)   #X
#endif

#ifndef __section
# define __section(NAME)                  \
   __attribute__((section(NAME), used))
#endif

#ifndef __section_tail
# define __section_tail(ID, KEY)          \
   __section(__stringify(ID) "/" __stringify(KEY))
#endif

#ifndef BPF_FUNC
# define BPF_FUNC(NAME, ...)              \
   (*NAME)(__VA_ARGS__) = (void *)BPF_FUNC_##NAME
#endif

#define BPF_JMP_MAP_ID   1

static void BPF_FUNC(tail_call, struct __sk_buff *skb, void *map,
                     uint32_t index);

struct bpf_elf_map jmp_map __section("maps") = {
    .type           = BPF_MAP_TYPE_PROG_ARRAY,
    .id             = BPF_JMP_MAP_ID,
    .size_key       = sizeof(uint32_t),
    .size_value     = sizeof(uint32_t),
    .pinning        = PIN_GLOBAL_NS,
    .max_elem       = 1,
};

__section_tail(BPF_JMP_MAP_ID, 0)
int looper(struct __sk_buff *skb)
{
    printk("skb cb: %u\n", skb->cb[0]++);
    tail_call(skb, &jmp_map, 0);
    return TC_ACT_OK;
}

__section("prog")
int entry(struct __sk_buff *skb)
{
    skb->cb[0] = 0;
    tail_call(skb, &jmp_map, 0);
    return TC_ACT_OK;
}

char __license[] __section("license") = "GPL";
```

当加载这个玩具程序时，tc 将创建程序数组并将其固定到 `jmp_map` 下全局命名空间中的 BPF 文件系统。此外，iproute2 中的 BPF ELF 加载器也会识别标记为 `__section_tail()` 的部分。 `struct bpf_elf_map` 中提供的 `id` 将与 `__section_tail()` 中的 id 标记进行匹配，即 `JMP_MAP_ID` ，因此加载程序在用户指定的程序数组映射索引处，在此示例中为 `0` 。因此，所有提供的尾部调用部分将由 iproute2 加载器填充到相应的映射中。该机制并非特定于 tc，而是可以应用于 iproute2 支持的任何其他 BPF 程序类型（例如 XDP、lwt）。

生成的 elf 包含描述地图 id 和该地图中的条目的节标题：

```bash
$ llvm-objdump -S --no-show-raw-insn prog_array.o | less
prog_array.o:   file format ELF64-BPF

Disassembly of section 1/0:
looper:
       0:       r6 = r1
       1:       r2 = *(u32 *)(r6 + 48)
       2:       r1 = r2
       3:       r1 += 1
       4:       *(u32 *)(r6 + 48) = r1
       5:       r1 = 0 ll
       7:       call -1
       8:       r1 = r6
       9:       r2 = 0 ll
      11:       r3 = 0
      12:       call 12
      13:       r0 = 0
      14:       exit
Disassembly of section prog:
entry:
       0:       r2 = 0
       1:       *(u32 *)(r1 + 48) = r2
       2:       r2 = 0 ll
       4:       r3 = 0
       5:       call 12
       6:       r0 = 0
       7:       exi
```

在本例中， `section 1/0` 指示 `looper()` 函数驻留在地图 id `1` 的位置 `0` 处。

固定的地图可以由用户空间应用程序（例如 Cilium 守护程序）检索，也可以由 tc 本身检索，以便使用新程序更新地图。更新以原子方式发生，首先从各个子系统触发的初始入口程序也以原子方式更新。

tc 执行尾调用映射更新的示例：

```bash
$ tc exec bpf graft m:globals/jmp_map key 0 obj new.o sec foo
```

如果 iproute2 将更新固定程序数组，则可以使用 `graft` 命令。通过将其指向 `globals/jmp_map` ，tc 将使用位于 `foo` 中的新程序来更新索引/键 `0` 处的映射。 /b4> .

#### 堆栈空间有限，最多 512 字节。

BPF 程序中的堆栈空间仅限于 512 字节，在用 C 语言实现 BPF 程序时需要仔细考虑这一点。但是，如前面第 3 点所述，具有单个条目的 `BPF_MAP_TYPE_PERCPU_ARRAY` 映射可以用于扩大暂存缓冲区空间。

#### 可以使用 BPF 内联组装

LLVM 6.0 或更高版本允许在可能需要的极少数情况下使用 BPF 内联汇编。下面的（废话）玩具示例显示了 64 位原子添加。由于缺乏文档， `lib/Target/BPF/BPFInstrInfo.td` 和 `test/CodeGen/BPF/` 中的 LLVM 源代码可能有助于提供一些其他示例。测试代码：

```bash
#include <linux/bpf.h>

#ifndef __section
# define __section(NAME)                  \
   __attribute__((section(NAME), used))
#endif

__section("prog")
int xdp_test(struct xdp_md *ctx)
{
    __u64 a = 2, b = 3, *c = &a;
    /* just a toy xadd example to show the syntax */
    asm volatile("lock *(u64 *)(%0+0) += %1" : "=r"(c) : "r"(b), "0"(c));
    return a;
}

char __license[] __section("license") = "GPL";
```

上述程序被编译成以下BPF指令序列：

```bash
Verifier analysis:

0: (b7) r1 = 2
1: (7b) *(u64 *)(r10 -8) = r1
2: (b7) r1 = 3
3: (bf) r2 = r10
4: (07) r2 += -8
5: (db) lock *(u64 *)(r2 +0) += r1
6: (79) r0 = *(u64 *)(r10 -8)
7: (95) exit
processed 8 insns (limit 131072), stack depth 8
```

#### 使用 #pragma pack 删除结构填充并对齐成员

在现代编译器中，数据结构默认对齐以有效地访问内存。结构成员被打包到内存地址，并添加填充以与处理器字大小正确对齐（例如，64 位处理器为 8 字节，32 位处理器为 4 字节）。因此，结构的大小通常可能会比预期的大。

```bash
struct called_info {
    u64 start;  // 8-byte
    u64 end;    // 8-byte
    u32 sector; // 4-byte
}; // size of 20-byte ?

printf("size of %d-byte\n", sizeof(struct called_info)); // size of 24-byte

// Actual compiled composition of struct called_info
// 0x0(0)                   0x8(8)
//  ↓________________________↓
//  |        start (8)       |
//  |________________________|
//  |         end  (8)       |
//  |________________________|
//  |  sector(4) |  PADDING  | <= address aligned to 8
//  |____________|___________|     with 4-byte PADDING.
```

内核中的 BPF 验证器检查 BPF 程序不会访问边界外或未初始化堆栈区域的堆栈边界。使用带有 padding 的 struct 作为映射值，将导致 `invalid indirect read from stack` 在 `bpf_prog_load()` 上失败。

示例代码：

```bash
struct called_info {
    u64 start;
    u64 end;
    u32 sector;
};

struct bpf_map_def SEC("maps") called_info_map = {
    .type = BPF_MAP_TYPE_HASH,
    .key_size = sizeof(long),
    .value_size = sizeof(struct called_info),
    .max_entries = 4096,
};

SEC("kprobe/submit_bio")
int submit_bio_entry(struct pt_regs *ctx)
{
    char fmt[] = "submit_bio(bio=0x%lx) called: %llu\n";
    u64 start_time = bpf_ktime_get_ns();
    long bio_ptr = PT_REGS_PARM1(ctx);
    struct called_info called_info = {
            .start = start_time,
            .end = 0,
            .sector = 0
    };

    bpf_map_update_elem(&called_info_map, &bio_ptr, &called_info, BPF_ANY);
    bpf_trace_printk(fmt, sizeof(fmt), bio_ptr, start_time);
    return 0;
}
```

`bpf_load_program()` 上的相应输出：

```bash
bpf_load_program() err=13
0: (bf) r6 = r1
...
19: (b7) r1 = 0
20: (7b) *(u64 *)(r10 -72) = r1
21: (7b) *(u64 *)(r10 -80) = r7
22: (63) *(u32 *)(r10 -64) = r1
...
30: (85) call bpf_map_update_elem#2
invalid indirect read from stack off -80+20 size 24
```

在 `bpf_prog_load()` 处，调用 eBPF 验证器 `bpf_check()` ，它将通过调用 `check_func_arg() -> check_stack_boundary()` 检查堆栈边界。从上面的错误显示， `struct called_info` 被编译为24字节大小，并且消息说从+20读取数据是无效的间接读取。正如我们之前讨论的，地址 0x14(20) 是 PADDING 所在的位置。

```bash
// Actual compiled composition of struct called_info
// 0x10(16)    0x14(20)    0x18(24)
//  ↓____________↓___________↓
//  |  sector(4) |  PADDING  | <= address aligned to 8
//  |____________|___________|     with 4-byte PADDING.
```

`check_stack_boundary()` 在内部循环遍历从起始指针开始的每个 `access_size` (24) 字节，以确保它位于堆栈边界内并且堆栈的所有元素都已初始化。由于不应该使用填充，因此它会出现“从堆栈中间接读取无效”的错误。为了避免这种失败，需要从结构中删除填充。

使用 `#pragma pack(n)` 指令删除填充：

```bash
#pragma pack(4)
struct called_info {
    u64 start;  // 8-byte
    u64 end;    // 8-byte
    u32 sector; // 4-byte
}; // size of 20-byte ?

printf("size of %d-byte\n", sizeof(struct called_info)); // size of 20-byte

// Actual compiled composition of packed struct called_info
// 0x0(0)                   0x8(8)
//  ↓________________________↓
//  |        start (8)       |
//  |________________________|
//  |         end  (8)       |
//  |________________________|
//  |  sector(4) |             <= address aligned to 4
//  |____________|                 with no PADDING.
```

通过将 `#pragma pack(4)` 定位在 `struct called_info` 之前，编译器会将结构体的成员对齐到至少 4 字节及其自然对齐方式。正如您所看到的， `struct called_info` 的大小已缩小为 20 字节，并且填充不再存在。

但是，去除填充也有缺点。例如，编译器将生成优化程度较低的代码。由于我们删除了填充，处理器将对结构进行未对齐的访问，这可能会导致性能下降。而且，在某些架构上，未对齐的访问可能会被验证者拒绝。

然而，有一种方法可以避免封装结构的缺点。只需在末尾添加显式填充 `u32 pad` 成员即可解决相同的问题，而无需打包结构。

```bash
struct called_info {
    u64 start;  // 8-byte
    u64 end;    // 8-byte
    u32 sector; // 4-byte
    u32 pad;    // 4-byte
}; // size of 24-byte ?

printf("size of %d-byte\n", sizeof(struct called_info)); // size of 24-byte

// Actual compiled composition of struct called_info with explicit padding
// 0x0(0)                   0x8(8)
//  ↓________________________↓
//  |        start (8)       |
//  |________________________|
//  |         end  (8)       |
//  |________________________|
//  |  sector(4) |  pad (4)  | <= address aligned to 8
//  |____________|___________|     with explicit PADDING.
```

#### 通过无效引用访问数据包数据

某些网络 BPF 辅助函数（例如 `bpf_skb_store_bytes` ）可能会更改数据包数据的大小。由于验证者无法跟踪此类更改，因此验证者对数据的任何先验引用都将无效。因此，在访问数据之前需要更新参考，以避免验证者拒绝程序。

为了说明这一点，请考虑以下代码片段：

```c
struct iphdr *ip4 = (struct iphdr *) skb->data + ETH_HLEN;

skb_store_bytes(skb, l3_off + offsetof(struct iphdr, saddr), &new_saddr, 4, 0);

if (ip4->protocol == IPPROTO_TCP) {
    // do something
}
```

由于取消引用无效的 `ip4->protocol` ，验证程序将拒绝该代码段：

```bash
R1=pkt_end(id=0,off=0,imm=0) R2=pkt(id=0,off=34,r=34,imm=0) R3=inv0
R6=ctx(id=0,off=0,imm=0) R7=inv(id=0,umax_value=4294967295,var_off=(0x0; 0xffffffff))
R8=inv4294967162 R9=pkt(id=0,off=0,r=34,imm=0) R10=fp0,call_-1
...
18: (85) call bpf_skb_store_bytes#9
19: (7b) *(u64 *)(r10 -56) = r7
R0=inv(id=0) R6=ctx(id=0,off=0,imm=0) R7=inv(id=0,umax_value=2,var_off=(0x0; 0x3))
R8=inv4294967162 R9=inv(id=0) R10=fp0,call_-1 fp-48=mmmm???? fp-56=mmmmmmmm
21: (61) r1 = *(u32 *)(r9 +23)
R9 invalid mem access 'inv'
```

要解决此问题，必须更新对 `ip4` 的引用：

```bash
struct iphdr *ip4 = (struct iphdr *) skb->data + ETH_HLEN;

skb_store_bytes(skb, l3_off + offsetof(struct iphdr, saddr), &new_saddr, 4, 0);

ip4 = (struct iphdr *) skb->data + ETH_HLEN;

if (ip4->protocol == IPPROTO_TCP) {
    // do something
}
```

## iproute2

有多种前端用于将 BPF 程序加载到内核中，例如 bcc、perf、iproute2 等。 Linux 内核源码树还在 `tools/lib/bpf/` 下提供了一个用户空间库，该库主要由 perf 使用和驱动，用于将 BPF 跟踪程序加载到内核中。然而，该库本身是通用的，不仅限于性能。 bcc 是一个工具包，提供许多有用的 BPF 程序，主要用于跟踪，这些程序通过嵌入 BPF C 代码的 Python  接口临时加载。不过，一般来说，前端之间实现 BPF 程序的语法和语义略有不同。此外，内核源代码树（ `samples/bpf/` ）中还有BPF示例，它们解析生成的目标文件并直接通过系统调用接口加载代码。

本节和前面的部分主要关注 iproute2 套件的 BPF 前端，用于加载 XDP、tc 或 lwt 类型的网络程序，因为 Cilium 的程序是针对此 BPF  加载器实现的。未来Cilium将配备原生BPF加载器，但程序仍将兼容通过iproute2套件加载，以方便开发和调试。

iproute2 支持的所有 BPF 程序类型共享相同的 BPF 加载器逻辑，因为具有作为库实现的公共加载器后端（iproute2 源代码树中的 `lib/bpf.c` ）。

上一节关于 LLVM 还介绍了一些与编写 BPF C 程序相关的 iproute2 部分，本文档的后面部分涉及编写程序时的 tc 和 XDP  特定方面。因此，本节将重点介绍使用 iproute2  加载目标文件的使用示例以及加载器的一些通用机制。它并不试图提供所有细节的完整覆盖，但足以入门。

### XDP BPF 目标文件的加载

假设已为 XDP 编译了 BPF 目标文件 `prog.o` ，则可以使用以下命令通过 `ip` 将其加载到名为 `em1` 的支持 XDP 的网络设备：

```bash
$ ip link set dev em1 xdp obj prog.o
```

上述命令假设程序代码位于默认部分，在 XDP 情况下称为 `prog` 。如果情况并非如此，并且该部分的名称不同，例如 `foobar` ，则需要将程序加载为：

```bash
$ ip link set dev em1 xdp obj prog.o sec foobar
```

上述命令假设程序代码位于默认部分，在 XDP 情况下称为 `prog` 。如果情况并非如此，并且该部分的名称不同，例如 `foobar` ，则需要将程序加载为：

```bash
$ ip link set dev em1 xdp obj prog.o sec foobar
```

请注意，也可以从 `.text` 部分加载程序。通过从 `xdp_drop` 入口点删除 `__section()` 注释来更改最小的独立 XDP 放置程序，如下所示：

```bash
#include <linux/bpf.h>

#ifndef __section
# define __section(NAME)                  \
   __attribute__((section(NAME), used))
#endif

int xdp_drop(struct xdp_md *ctx)
{
    return XDP_DROP;
}

char __license[] __section("license") = "GPL";
```

并且可以如下加载：

```bash
$ ip link set dev em1 xdp obj prog.o sec .text
```

默认情况下，如果 XDP 程序已附加到网络接口， `ip` 将抛出错误，以防止它被意外覆盖。为了用新程序替换当前运行的 XDP 程序，必须使用 `-force` 选项：

```bash
$ ip -force link set dev em1 xdp obj prog.o
```

如今，大多数支持 XDP 的驱动程序都支持用新程序原子替换现有程序，而不会中断流量。由于性能原因，始终只有一个程序附加到启用 XDP 的驱动程序，因此不支持程序链。然而，如上一节所述，必要时可以通过尾调用来执行程序分区，以实现类似的用例。

如果接口附加了 XDP 程序， `ip link` 命令将显示 `xdp` 标志。因此， `ip link | grep xdp` 可用于查找所有运行 XDP 的接口。通过 `ip -d link` 和 `bpftool` 的详细视图提供了进一步的自省功能，可用于根据 `ip link` 转储。

为了从接口中删除现有的 XDP 程序，必须发出以下命令：

```bash
$ ip link set dev em1 xdp off
```

在将驱动程序的操作模式从非 XDP 切换到本机 XDP 的情况下，反之亦然，驱动程序通常需要重新配置其接收（和发送）环，以确保接收到的数据包在单页内线性设置，以便  BPF读取并写入。然而，一旦完成，大多数驱动程序只需要在请求交换 BPF 程序时执行程序本身的原子替换。

总的来说，XDP 支持 iproute2 实现的三种操作模式： `xdpdrv` 、 `xdpoffload` 和 `xdpgeneric` 。

`xdpdrv` 代表本机 XDP，这意味着 BPF 程序最早在软件中直接在驱动程序的接收路径中运行。这是正常/传统的 XDP 模式，需要驱动程序来实现 XDP 支持，上游 Linux 内核中的所有主要 10G/40G/+ 网络驱动程序都已提供。

`xdpgeneric` 代表通用 XDP，旨在作为尚不支持本机 XDP 的驱动程序的实验测试台。鉴于入口路径中的通用 XDP 挂钩出现的时间要晚得多，此时数据包已经作为 `skb` 进入堆栈的主接收路径，因此性能明显低于 `xdpdrv` 因此，大多数情况下仅对实验感兴趣，对生产环境较少。

最后但并非最不重要的一点是， `xdpoffload`  模式由SmartNIC实现，例如Netronome的nfp驱动程序支持的那些，并允许将整个BPF/XDP程序卸载到硬件中，因此该程序在每个数据包接收时直接在卡片。这提供了比在本机 XDP 中运行更高的性能，尽管与本机 XDP 相比，并非所有 BPF 映射类型或 BPF 辅助函数都可供使用。在这种情况下，BPF  验证者将拒绝该程序并向用户报告不支持的内容。除了停留在受支持的 BPF 功能和辅助函数范围内之外，在编写 BPF C  程序时无需采取特殊的预防措施。

当使用像 `ip link set dev em1 xdp obj [...]` 这样的命令时，内核将尝试首先将程序作为本机 XDP 加载，如果驱动程序不支持本机 XDP，它将自动回退到通用 XDP。因此，例如，显式使用 `xdpdrv` 而不是 `xdp` ，内核只会尝试将程序加载为本机 XDP，并在驱动程序不支持它的情况下失败，这提供了保证完全避免通用 XDP。

强制以本机 XDP 模式加载 BPF/XDP 程序、转储链接详细信息并再次卸载程序的示例：

```bash
# ip -force link set dev em1 xdpdrv obj prog.o
# ip link show
[...]
6: em1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 xdp qdisc mq state UP mode DORMANT group default qlen 1000
    link/ether be:08:4d:b6:85:65 brd ff:ff:ff:ff:ff:ff
    prog/xdp id 1 tag 57cd311f2e27366b
[...]
# ip link set dev em1 xdpdrv off
```

现在使用相同的示例强制通用 XDP，即使驱动程序支持本机 XDP，并另外通过 bpftool 转储附加虚拟程序的 BPF 指令：

```bash
# ip -force link set dev em1 xdpgeneric obj prog.o
# ip link show
[...]
6: em1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 xdpgeneric qdisc mq state UP mode DORMANT group default qlen 1000
    link/ether be:08:4d:b6:85:65 brd ff:ff:ff:ff:ff:ff
    prog/xdp id 4 tag 57cd311f2e27366b                <-- BPF program ID 4
[...]
# bpftool prog dump xlated id 4                       <-- Dump of instructions running on em1
0: (b7) r0 = 1
1: (95) exit
# ip link set dev em1 xdpgeneric off
```

最后但并非最不重要的卸载 XDP，我们还通过 bpftool 转储程序信息以检索一般元数据：

```bash
# ip -force link set dev em1 xdpoffload obj prog.o
# ip link show
[...]
6: em1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 xdpoffload qdisc mq state UP mode DORMANT group default qlen 1000
    link/ether be:08:4d:b6:85:65 brd ff:ff:ff:ff:ff:ff
    prog/xdp id 8 tag 57cd311f2e27366b
[...]
# bpftool prog show id 8
8: xdp  tag 57cd311f2e27366b dev em1                  <-- Also indicates a BPF program offloaded to em1
    loaded_at Apr 11/20:38  uid 0
    xlated 16B  not jited  memlock 4096B
# ip link set dev em1 xdpoffload off
```

请注意，不可能同时使用 `xdpdrv` 和 `xdpgeneric` 或其他模式，这意味着只能选择一种 XDP 操作模式。

不同 XDP 模式之间的切换，例如从通用到本机或反之亦然在原子上是不可能的。仅在特定操作模式下切换程序：

```bash
# ip -force link set dev em1 xdpgeneric obj prog.o
# ip -force link set dev em1 xdpoffload obj prog.o
RTNETLINK answers: File exists
# ip -force link set dev em1 xdpdrv obj prog.o
RTNETLINK answers: File exists
# ip -force link set dev em1 xdpgeneric obj prog.o    <-- Succeeds due to xdpgeneric
#
```

模式之间的切换需要先离开当前的操作模式，然后才能进入新的操作模式：

```bash
# ip -force link set dev em1 xdpgeneric obj prog.o
# ip -force link set dev em1 xdpgeneric off
# ip -force link set dev em1 xdpoffload obj prog.o
# ip l
[...]
6: em1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 xdpoffload qdisc mq state UP mode DORMANT group default qlen 1000
    link/ether be:08:4d:b6:85:65 brd ff:ff:ff:ff:ff:ff
    prog/xdp id 17 tag 57cd311f2e27366b
[...]
# ip -force link set dev em1 xdpoffload off
```

### 加载 tc BPF 目标文件

假设已经为 tc 编译了 BPF 目标文件 `prog.o` ，则可以通过 tc 命令将其加载到网络设备。与 XDP 不同，不存在支持将 BPF 程序附加到设备的驱动程序依赖性。这里，网络设备称为 `em1` ，使用以下命令可以将程序附加到 `em1` 的网络 `ingress` 路径：

```bash
# tc qdisc add dev em1 clsact
# tc filter add dev em1 ingress bpf da obj prog.o
```

第一步是设置 `clsact` qdisc（Linux 排队规则）。 `clsact` 是一个类似于 `ingress` qdisc的虚拟qdisc，它只能保存分类器和动作，但不执行实际的排队。为了附加 `bpf` 分类器，需要它。 `clsact` qdisc 提供了两个名为 `ingress` 和 `egress` 的特殊钩子，可以将分类器附加到其中。 `ingress` 和 `egress` 挂钩都位于网络数据路径中的中央接收和传输位置，设备上的每个数据包都经过这里。 `ingress` 钩子是从内核中的 `__netif_receive_skb_core() -> sch_handle_ingress()` 调用的， `egress` 钩子是从 `__dev_queue_xmit() -> sch_handle_egress()` 调用的。

将程序附加到 `egress` 挂钩的等效操作如下所示：

```bash
# tc filter add dev em1 egress bpf da obj prog.o
```

`clsact` qdisc 从 `ingress` 和 `egress` 方向进行无锁处理，并且还可以附加到虚拟的无队列设备，例如 `veth` 连接容器的设备。

在挂钩旁边， `tc filter` 命令选择要在 `da` （直接操作）模式下使用的 `bpf` 。建议使用 `da` 模式，并且应始终指定该模式。它基本上意味着 `bpf` 分类器不需要调用外部 tc 操作模块，这对于 `bpf` 来说并不是必需的，因为所有数据包修改、转发或其他类型的操作都可以已经在要附加的单个 BPF 程序内执行，因此速度明显更快。

此时，程序已被附加，并在数据包穿过设备后执行。就像在 XDP 中一样，如果不使用默认的节名称，则可以在加载期间指定它，例如，在节 `foobar` 的情况下：

iproute2 的 BPF 加载器允许跨程序类型使用相同的命令行语法，因此 `obj prog.o sec foobar` 与前面提到的 XDP 的语法相同。

可以通过以下命令列出附加程序：

```bash
# tc filter show dev em1 ingress
filter protocol all pref 49152 bpf
filter protocol all pref 49152 bpf handle 0x1 prog.o:[ingress] direct-action id 1 tag c5f7825e5dac396f

# tc filter show dev em1 egress
filter protocol all pref 49152 bpf
filter protocol all pref 49152 bpf handle 0x1 prog.o:[egress] direct-action id 2 tag b2fd5adc0f262714
```

`prog.o:[ingress]` 的输出表明程序段 `ingress` 是从文件 `prog.o` 加载的，并且 `bpf` 在 `direct-action` 模式。为每种情况附加程序 `id` 和 `tag` ，其中后者表示指令流上的散列，可以与目标文件或 `perf` 报告相关联最后但并非最不重要的一点是， `id` 表示系统范围内唯一的 BPF 程序标识符，可以与 `bpftool` 一起使用来进一步检查或转储附加的 BPF 程序。

tc 不仅可以附加一个 BPF 程序，它还提供可以链接在一起的各种其他分类器。然而，附加单个 BPF 程序就足够了，因为借助 `da` ( `direct-action` ) 模式，所有数据包操作都可以包含在程序本身中，这意味着 BPF 程序本身已经返回tc 操作判决，例如 `TC_ACT_OK` 、 `TC_ACT_SHOT` 等。为了获得最佳性能和灵活性，这是推荐的用法。

在上面的 `show` 命令中，tc 还在 BPF 相关输出旁边显示 `pref 49152` 和 `handle 0x1` 。如果未通过命令行显式提供，两者都会自动生成。 `pref` 表示优先级编号，这意味着如果附加了多个分类器，它们将根据升序优先级执行， `handle` 表示一个标识符，如果同一分类器有多个实例已加载到相同的 `pref` 下。由于在 BPF 的情况下，单个程序就完全足够了，因此通常可以忽略 `pref` 和 `handle` 。

仅在计划以原子方式替换附加的 BPF 程序的情况下，建议在初始加载时显式指定先验 `pref` 和 `handle` ，以便它们不具有稍后查询 `replace` 操作。因此，创造就变成了：

```bash
# tc filter add dev em1 ingress pref 1 handle 1 bpf da obj prog.o sec foobar

# tc filter show dev em1 ingress
filter protocol all pref 1 bpf
filter protocol all pref 1 bpf handle 0x1 prog.o:[foobar] direct-action id 1 tag c5f7825e5dac396f
```

对于原子替换，可以发出以下命令，用 `foobar` 部分中的文件 `prog.o` 中的新 BPF 程序更新 `ingress` 钩子处的现有程序：

```bash
# tc filter replace dev em1 ingress pref 1 handle 1 bpf da obj prog.o sec foobar
```

最后但并非最不重要的一点是，为了从 `ingress` 和 `egress` 挂钩中删除所有附加程序，可以使用以下命令：

```bash
# tc filter del dev em1 ingress
# tc filter del dev em1 egress
```

为了从网络设备中删除整个 `clsact` qdisc，这也隐式地从 `ingress` 和 `egress` 挂钩中删除所有附加的程序，提供了以下命令：

```bash
# tc qdisc del dev em1 clsact
```

如果 NIC 和驱动程序支持它，则也可以卸载 tc BPF 程序，与 XDP BPF 程序类似。 Netronome 的 nfp 支持的 NIC 提供两种类型的 BPF 卸载。

```bash
# tc qdisc add dev em1 clsact
# tc filter replace dev em1 ingress pref 1 handle 1 bpf skip_sw da obj prog.o
Error: TC offload is disabled on net device.
We have an error talking to the kernel
```

如果显示上述错误，则首先需要通过 ethtool 的 `hw-tc-offload` 设置为设备启用 tc hardware offload：

```bash
# ethtool -K em1 hw-tc-offload on
# tc qdisc add dev em1 clsact
# tc filter replace dev em1 ingress pref 1 handle 1 bpf skip_sw da obj prog.o
# tc filter show dev em1 ingress
filter protocol all pref 1 bpf
filter protocol all pref 1 bpf handle 0x1 prog.o:[classifier] direct-action skip_sw in_hw id 19 tag 57cd311f2e27366b
```

`in_hw` 标志确认程序已卸载到 NIC。

请注意，tc 和 XDP 的 BPF 卸载不能同时加载，必须选择 tc 或 XDP 卸载选项。

### 通过 netdevsim 驱动程序测试 BPF 卸载接口

netdevsim 驱动程序是 Linux 内核的一部分，提供了一个虚拟驱动程序，该驱动程序实现了 XDP BPF 和 tc BPF 程序的卸载接口，并有助于测试内核更改或直接针对内核 UAPI 实现控制平面的低级用户空间程序。

可以按如下方式创建 netdevsim 设备：

```bash
# modprobe netdevsim
// [ID] [PORT_COUNT]
# echo "1 1" > /sys/bus/netdevsim/new_device
# devlink dev
netdevsim/netdevsim1
# devlink port
netdevsim/netdevsim1/0: type eth netdev eth0 flavour physical
# ip l
[...]
4: eth0: <BROADCAST,NOARP,UP,LOWER_UP> mtu 1500 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
    link/ether 2a:d5:cd:08:d1:3f brd ff:ff:ff:ff:ff:ff
```

完成该步骤后，可以测试加载 XDP BPF 或 tc BPF 程序，如前面的各个示例所示：

```bash
# ip -force link set dev eth0 xdpoffload obj prog.o
# ip l
[...]
4: eth0: <BROADCAST,NOARP,UP,LOWER_UP> mtu 1500 xdpoffload qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
    link/ether 2a:d5:cd:08:d1:3f brd ff:ff:ff:ff:ff:ff
    prog/xdp id 16 tag a04f5eef06a7f555
```

这两个工作流程是使用 iproute2 分别加载 XDP BPF 和 tc BPF 程序的基本操作。

BPF 加载器还有其他各种高级选项，适用于 XDP 和 tc，此处列出了其中一些。为了简单起见，在示例中仅提供了 XDP。

1. #### 即使成功也会输出详细的日志

  可以附加选项 `verb` 来加载程序，以便转储验证程序日志，即使没有发生错误：

  ```bash
  # ip link set dev em1 xdp obj xdp-example.o verb 
  
  Prog section 'prog' loaded (5)!
   - Type:         6
   - Instructions: 2 (0 over limit)
   - License:      GPL
  
  Verifier analysis:
  
  0: (b7) r0 = 1
  1: (95) exit
  processed 2 insns
  ```

2. #### 加载已固定在 BPF 文件系统中的程序

  iproute2 不是从目标文件加载程序，而是可以从 BPF 文件系统检索程序，以防某些外部实体将其固定在那里并将其附加到设备：

  ```bash
  # ip link set dev em1 xdp pinned /sys/fs/bpf/prog
  ```

  iproute2 还可以使用与检测到的 BPF 文件系统挂载点相关的缩写形式：

  ```bash
  ip link set dev em1 xdp pinned m:prog
  ```



当加载BPF程序时，iproute2会自动检测已挂载的文件系统实例，以便执行节点的固定。如果没有找到已挂载的 BPF 文件系统实例，则 tc 会自动将其挂载到 `/sys/fs/bpf/` 下的默认位置。

如果已经找到实例，则将使用该实例并且不会执行额外的安装：

```bash
# mkdir /var/run/bpf
# mount --bind /var/run/bpf /var/run/bpf
# mount -t bpf bpf /var/run/bpf
# tc filter add dev em1 ingress bpf da obj tc-example.o sec prog
# tree /var/run/bpf
/var/run/bpf
+-- ip -> /run/bpf/tc/
+-- tc
|   +-- globals
|       +-- jmp_map
+-- xdp -> /run/bpf/tc/

4 directories, 1 file
```

默认情况下，tc 将创建一个如上所示的初始目录结构，其中所有子系统用户将通过 `globals` 命名空间的符号链接指向同一位置，以便固定的 BPF 映射可以在各种 BPF 程序类型之间重用在iproute2中。如果文件系统实例已被安装并且现有结构已存在，则 tc 将不会覆盖它。这可能是分离 `lwt` 、 `tc` 和 `xdp` 映射的情况，以便不在所有映射之间共享 `globals` 。

正如前面的 LLVM 部分简要介绍的那样，iproute2 将在安装时安装一个头文件，BPF 程序可以通过标准包含路径包含该头文件：

```bash
#include <iproute2/bpf_elf.h>
```

该头文件的目的是为程序使用的映射和默认节名称提供 API。它是 iproute2 和 BPF 程序之间的稳定契约。

iproute2 的映射定义是 `struct bpf_elf_map` 。其成员已在本文档前面的 LLVM 部分介绍过。

当解析 BPF 目标文件时，iproute2 加载器将遍历所有 ELF 部分。它最初获取 `maps` 和 `license` 等辅助部分。对于 `maps` ，将检查 `struct bpf_elf_map` 数组的有效性，并在需要时执行兼容性解决方法。随后，所有地图都使用用户提供的信息创建，或者作为固定对象检索，或者新创建然后固定到 BPF  文件系统中。接下来，加载器将处理所有包含 ELF 映射重定位条目的程序段，这意味着将映射文件描述符加载到寄存器中的 BPF  指令将被重写，以便相应的映射文件描述符被编码到指令立即值中，以便内核能够稍后能够将它们转换为映射内核指针。之后，所有程序本身都通过 BPF  系统调用创建，并且尾部调用映射（如果存在），并使用程序的文件描述符进行更新。





















