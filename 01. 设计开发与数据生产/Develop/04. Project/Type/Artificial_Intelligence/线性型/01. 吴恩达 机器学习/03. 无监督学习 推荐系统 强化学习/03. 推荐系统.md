# 吴恩达机器学习

# 目录

# 推荐系统（Recommender Systems）

（一般是多用户回归的例子）

## 协同过滤（Collaborative Filtering）

### 线性回归

#### 例子 - 电影评价预测

预测电影评价，根据用户对一些电影的评价去给他推荐电影（这里的评分是0~5星）
然后我们要预测用户对某部电影的评价分数会是多少

| 电影名               | 中文翻译     | 用户1 评分 | 用户2 评分 | 用户3 评分 | 用户4 评分 |
| -------------------- | ------------ | ---------- | ---------- | ---------- | ---------- |
| Love at last         | 真心男儿     | 5          | 5          | 0          | 0          |
| Romance forever      | 罗曼史       | 5          | ？         | ？         | 0          |
| Cute puppies of love | 可爱小狗     | ？         | 4          | 0          | ？         |
| Nonstop car chases   | 汽车追逐     | 0          | 0          | 5          | 4          |
| Swrods vs. karate    | 剑客vs空手道 | 0          | 0          | 5          | ？         |

#### 根据特征预测

电影的特征是什么？比如用 浪漫程度、动作程度 作为特征

| 电影名               | 中文翻译     | 用户1 评分 | 用户2 评分 | 用户3 评分 | 用户4 评分 | $x_1$(浪漫程度) | $x_2$(动作程度) |
| -------------------- | ------------ | ---------- | ---------- | ---------- | ---------- | --------------- | --------------- |
| Love at last         | 真心男儿     | 5          | 5          | 0          | 0          | 0.9             | 0               |
| Romance forever      | 罗曼史       | 5          | ？         | ？         | 0          | 1.0             | 0.01            |
| Cute puppies of love | 可爱小狗     | ？         | 4          | 0          | ？         | 0.99            | 0               |
| Nonstop car chases   | 汽车追逐     | 0          | 0          | 5          | 4          | 0.1             | 1.0             |
| Swrods vs. karate    | 剑客vs空手道 | 0          | 0          | 5          | ？         | 0               | 0.9             |

一些参数符号：
$$
~一些参数：\\
\begin{aligned}
    n_u=&4&&用户数\text{（User)}\\
    n_m=&5&&电影数\text{（Movie)}\\
    n=&2&&特征数\\
    i~~~~~&&&电影序\\
    j~~~~~&&&用户序\\
    k~~~~~&&&特征序?\\
    x^{(i)}=&x_m^{(i)}=v_m^{(i)}&&第i部电影的特征\\
    w^{(j)}=&w_u^{(j)}=v_u^{(j)}&&第j个用户的特征\_1\\
    b^{(j)}=&b_u^{(j)}&&第j个用户的特征\_2\\
    \hat y^{(i,j)}=&w^{(j)}\cdot x^{(i)}+b^{(j)}&&拟合模型
\end{aligned}
$$
可以用**电影特征+用户喜好**预测**用户评价**：
$$
尝试用电影3的特征+用户1的喜好，来预测用户1对电影3的评价：\\~\\
\begin{aligned}
    w^{(1)}=&\begin{bmatrix}5\\0\end{bmatrix}&&第1个用户~模型参数\\
    b^{(1)}=&0&&第1个用户~模型参数\\
    x^{(3)}=&\begin{bmatrix}0.99\\0\end{bmatrix}&&第3部电影的特征\\
    \hat y^{(3,1)}=&w^{(1)}\cdot x^{(3)}+b^{(1)}&&第1个用户对第3部电影的评价\\
    =&4.95
\end{aligned}
$$
Loss函数依然是平方误差公式，成本函数为：
$$
\min_{w^{(j)},b^{(j)}}J(w^{(j)},b^{(j)})
=\frac{1}{2m^{(j)}}\sum_{i:r(i,j)=1}
{\color{red}(w^{(j)}\cdot x^{(i)}+b^{(j)}-y^{(i,j)})^2}+
{\color{orange}\frac \lambda{2m^{(j)}}\sum^n_{k=1}(w_k^{(j)})^2}
$$

#### 协同过滤算法（Collaborative Filtering Algorithm）

前面的$x_1$和$x_2$是已经给出的，这期会学习如何自动得出

| 电影名               | 中文翻译     | 用户1 评分 | 用户2 评分 | 用户3 评分 | 用户4 评分 | $x_1$~~(浪漫程度)~~ | $x_2$~~(动作程度)~~ |
| -------------------- | ------------ | ---------- | ---------- | ---------- | ---------- | ------------------- | ------------------- |
| Love at last         | 真心男儿     | 5          | 5          | 0          | 0          | ？                  | ？                  |
| Romance forever      | 罗曼史       | 5          | ？         | ？         | 0          | ？                  | ？                  |
| Cute puppies of love | 可爱小狗     | ？         | 4          | 0          | ？         | ？                  | ？                  |
| Nonstop car chases   | 汽车追逐     | 0          | 0          | 5          | 4          | ？                  | ？                  |
| Swrods vs. karate    | 剑客vs空手道 | 0          | 0          | 5          | ？         | ？                  | ？                  |

既可以用**电影特征+用户喜好**预测**用户评价**：
$$
尝试用电影3的特征+用户1的喜好，来预测用户1对电影3的评价：\\~\\
\begin{aligned}
    w^{(1)}=&\begin{bmatrix}5\\0\end{bmatrix}&&第1个用户~模型参数\\
    b^{(1)}=&0&&第1个用户~模型参数\\
    x^{(3)}=&\begin{bmatrix}0.99\\0\end{bmatrix}&&第3部电影的特征\\
    \hat y^{(3,1)}=&w^{(1)}\cdot x^{(3)}+b^{(1)}&&第1个用户对第3部电影的评价\\
    =&4.95
\end{aligned}
$$
也可以用**用户评价**计算**电影特征**：
$$
尝试用4个用户的评分，来绩电影1的特征：\\~\\
\begin{matrix}
    w^{(1)}=\begin{bmatrix}5\\0\end{bmatrix}&
    w^{(2)}=\begin{bmatrix}5\\0\end{bmatrix}&
    w^{(3)}=\begin{bmatrix}0\\5\end{bmatrix}&
    w^{(4)}=\begin{bmatrix}0\\5\end{bmatrix}\\

    b^{(1)}=0&
    b^{(2)}=0&
    b^{(3)}=0&
    b^{(4)}=0
\end{matrix}\\~\\

因为~\hat y^{(i,j)}=w^{(j)}\cdot x^{(i)}+b^{(j)}，\\
\left.\begin{matrix}
    w^{(1)}\cdot x^{(1)}\approx 5\\ 
    w^{(2)}\cdot x^{(1)}\approx 5\\
    w^{(3)}\cdot x^{(1)}\approx 0\\
    w^{(4)}\cdot x^{(1)}\approx 0
\end{matrix}\right\}~
x^{(1)}=\begin{bmatrix}1\\0\end{bmatrix}
$$
那么将两者结合，**协同过滤算法**：

$$
用代价函数去学习：w^{(1)},b^{(1)},\cdots,w^{(n_u)},b^{(n_u)}:\\

\min J(w^{(1)},b^{(1)},\cdots,w^{(n_u)},b^{(n_u)})=
\frac 12\sum^{n_u}_{j=1}\sum_{i:r(i,j)=1}
{\color{red}(w^{(j)}\cdot x^{(i)}+b^{(j)}-y^{(i,j)})^2}+
{\color{orange}\frac\lambda2\sum^{n_u}_{j=1}\sum^{n}_{k=1}(w_k^{(j)})^2}\\~\\

用代价函数去学习：x^{(1)},\cdots,x^{(n_m)}:\\

\min J(x^{(1)},x^{(2)},\cdots,x^{(n_m)})=
\frac 12\sum^{n_m}_{i=1}\sum_{j:r(i,j)=1}
{\color{red}(w^{(j)}\cdot x^{(i)}+b^{(j)}-y^{(i,j)})^2}+
{\color{orange}\frac\lambda2\sum^{n_m}_{i=1}\sum^{n}_{k=1}(x_k^{(i)})^2}\\~\\

将他们组合起来：\\

\min J(\vec w,\vec b,\vec x)=
\frac 12\sum_{(i,j):r(i,j)=1}
{\color{red}(w^{(j)}\cdot x^{(i)}+b^{(j)}-y^{(i,j)})^2}+
{\color{orange}\frac\lambda2\sum^{n_u}_{j=1}\sum^{n}_{k=1}(w_k^{(j)})^2}+
{\color{orange}\frac\lambda2\sum^{n_m}_{i=1}\sum^{n}_{k=1}(x_k^{(i)})^2}
$$
梯度下降，最优化
$$
w_i^{(j)}:=w_i^{(j)}-\alpha\frac{\partial}{\partial w_i^{(j)}}J(\vec w,\vec b,\vec x)\\
b^{(j)}:=b^{(j)}-\alpha\frac{\partial}{\partial b^{(j)}}J(\vec w,\vec b,\vec x)\\
x_k^{(i)}:=x_k^{(i)}-\alpha\frac{\partial}{\partial x_k^{(i)}}J(\vec w,\vec b,\vec x)\\
$$



### 逻辑回归

#### 二进制标签（Binary labels）

二进制标签，例如：喜欢、赞、点击过
（Binary labels：favs, likes and clicks）

实例应用举例：

- 用户$J$在被展示后购买了商品吗？
- 用户$J$是否喜欢某件物品？
- 用户$J$是否在该项上花费了至少30秒的时间？
- 用户$J$是否点击了一个项目？



#### 例子 - 推荐系统（Recommended Systems）

| 电影名               | 中文翻译     | 用户1 点赞 | 用户2 点赞 | 用户3 点赞 | 用户4 点赞 |
| -------------------- | ------------ | ---------- | ---------- | ---------- | ---------- |
| Love at last         | 真心男儿     | 1          | 1          | 0          | 0          |
| Romance forever      | 罗曼史       | 1          | ？         | ？         | 0          |
| Cute puppies of love | 可爱小狗     | ？         | 1          | 0          | ？         |
| Nonstop car chases   | 汽车追逐     | 0          | 0          | 1          | 1          |
| Swrods vs. karate    | 剑客vs空手道 | 0          | 0          | 1          | ？         |



接下来的做法就是将上一个例子中的线性回归变成逻辑回归：
$$
通用成本函数：f_{(w,b,x)}(x)=g(w^{(j)}\cdot x^{(i)}+b^{(j)})\\~\\

预测的成本函数：\\
\min J(\vec w,\vec b,\vec x)=
\frac 12\sum_{(i,j):r(i,j)=1}
{\color{red}(w^{(j)}\cdot x^{(i)}+b^{(j)}-y^{(i,j)})^2}+
{\color{orange}\frac\lambda2\sum^{n_u}_{j=1}\sum^{n}_{k=1}(w_k^{(j)})^2}+
{\color{orange}\frac\lambda2\sum^{n_m}_{i=1}\sum^{n}_{k=1}(x_k^{(i)})^2}

\\~\\二元分类的成本函数：\\
Loss：L(f_{(w,b,x)}(x),y^{(i,j)})=
-y^{(i,j)}\log\left(f_{(w,b,x)}(x)\right)-(1-y^{(i,j)})\log\left(1-f_{(w,b,x)}(x)\right)\\

\min J(\vec w,\vec b,\vec x)=
\frac 12\sum_{(i,j):r(i,j)=1}
{\color{red}L(f_{(w,b,x)}(x),y^{(i,j)})}
$$



### 协同过滤 - TensorFlow实现

手动实现（使用梯度下降）

```python
w = tf.Variable(3.0)
x = 1.0
y = 1.0			# 目标值
alpha = 0.01

iterations = 30
for iter in range(iterations):
    # 使用TensorFlow的渐变磁带来记录步骤
    # 用来计算成本J，以实现自动微分
    with tf.GradientTape() as tape:
        fwb = w*x
        costJ = (fwb-y)**2
        
    # 使用梯度带计算成本相对于参数w的梯度
    [dJdw] = tape.gradient(costJ, [w])
    
    # 通过更新w的值来运行一步梯度下降以降低成本
    w.assign_add(-alpha * dJdw)
```



TensorFlow包实现

```python
# 实例化一个优化器
optimizer = keras.optimizers.Adam (learnina rate=1e-1)

iterations = 200
for iter in range (iterations):
    # 使用TensorFlow的GradientTape来记录用于计算成本的操作
    with tf.GradientTape() as tape:
	
        # 计算成本 (前向传递包含在成本中)
        cost_value = cofiCostruncV(X, W, b, Ynorm, R,
            num_users, num_movies, lambda)

    # 使用梯度带自动检索可训练变量相对于损失的梯度
	grads = tape.gradient( cost_value, [X,W,b] )

    # 通过更新变量的值来运行一步梯度下降，以最小化Loss
    optimizer.apply_gradients ( zip(grads, [X,W,b]) )

```

![image-20220919211256111](03. 推荐系统.assets/image-20220919211256111.png)



## 新用户 / 新项

### 均值归一化（Mean Normalization）

> 话说矩阵的归一化，挺常见的。之前学unity shared时，好像也有过类似的操作



均值归一化作用：能使算法运行得更快一点



#### 新用户

假如有一个新用户，他没有对任何一部电影评分，我们要去预测他的行为，那么要先将原来的数据进行 均值归一化

这样可以规范那一列，好处是如果有一大群新用户，那么会有数列都是0。进行矩阵运算时，能十分好地去简化运算，使运算更快

![image-20220919203513333](03. 推荐系统.assets/image-20220919203513333.png)

![image-20220919204026789](03. 推荐系统.assets/image-20220919204026789.png)

#### 新电影

假如有一部新电影，也需要去均值归一化吗？去规范那一行吗？

好像说是不如新用户需求高，可以不均值归一化

另外，对于推荐算法，一开始就不要将这部没有评分的电影展示给太多用户



### 寻找相关特征

#### 寻找关联项（Finding related items）

项目$i$的特征$x^{(i)}$很难解释，要找到与之相关的其他项。
找到与$x^{(i)}$相似的$x^{(k)}$，从而找到与项$i$相似的项$k$（比如找到与某电影相关的其他电影）
也就是，找最小的距离的项：
$$
\sum^n_{l=1}(x_l^{(k)}-x_l^{(i)})^2
$$


#### 协同过滤的局限性

Q：Cold Start（?冷启动?）问题，如何去：

- 新项：对那些几乎没有用户评价过的新项进行排名？
- 新用户：向评分数很少的新用户展示一些合适的东西？

A：可以使用项或用户的侧面信息：

- 项：类型、电影明星、工作室
- 用户：人口统计 (年龄，性别，地址)，表现的喜好，……



## 基于内容过滤（Content-based Filtering）

### 协同过滤 vs 基于内容过滤

原理

- 协同过滤：
  - 根据给予与您相似的评分的用户的评分，向您推荐项目
- 基于内容过滤：
  - 根据用户和项目的特点向您推荐项目，以找到合适的匹配项



工作方式

- 用户特征：$x_u^{(j)}$对应`user[j]`
  - 年龄
  - 性别
  - 性别
  - 城市
  - 看过的电影
  - 每种类型的平均评级
- 电影特征：$x_m^{(i)}$对应`movie[i]`
  - 年份
  - 类型
  - 点评
  - 平均评级



### 基于内容过滤

比如
$$
w^{(j)}\cdot x^{(i)}\rightarrow v_u^{(j)}\cdot v_m^{(j)}\\~\\

用户特征：x_u^{j}=v_u^{(j)}=\begin{bmatrix}4.9\\0.1\\\vdots\\3.0\end{bmatrix}
\begin{bmatrix}likes\\likes\\\vdots\\~~likes~~\end{bmatrix}
\\~\\


电影特征：x_m^{i}=v_m^{(i)}=\begin{bmatrix}4.5\\0.2\\\vdots\\3.5\end{bmatrix}
\begin{bmatrix}浪漫程度\\动作程度\\\vdots\\~\end{bmatrix}
$$


### 基于内容过滤 - 的深度学习方法

将用户网络和电影网络回执成两个独立的神经网络，然后再将他们合并成一个单一的神经网络

![image-20220920133100646](03. 推荐系统.assets/image-20220920133100646.png)

![image-20220920133653546](03. 推荐系统.assets/image-20220920133653546.png)

成本函数：
$$
\min J(\vec v_u,\vec v_m)=
\frac 12\sum_{(i,j):r(i,j)=1}
{\color{red}(v_u^{(j)}\cdot v_m^{(i)}-y^{(i,j)})^2}+
{\color{orange}\frac\lambda2\sum^{n_u}_{j=1}\sum^{n}_{k=1}(v_{u,k}^{(j)})^2}+
{\color{orange}\frac\lambda2\sum^{n_m}_{i=1}\sum^{n}_{k=1}(v_{m,k}^{(i)})^2}
$$
Q：目的：去寻找与电影$i$相似的其他电影
A：实现：即求尽量小的$||v_m^{(k)}-v_m^{(i)}||^2$



### 基于内容过滤 - 的TensorFlow实现

```python
# 用户的神经网络
user_NN = tf.keras.models.sequential([
	tf.keras.layers.Dense (256, activation='relu'),
    tf.keras.layers.Dense (128, activation='relu'),
    tf.keras.layers.Dense (32)
])

# 项目的神经网络
item_NN = tf.keras.models.sequential([
	tf.keras.layers.Dense (256, activation='relu'),
    tf.keras.layers.Dense (128, activation='relu'),
    tf.keras.layers.Dense (32)
])

# 创建用户输入并指向基本网络
input_user = tf.keras.layers.Input(shape=(num_user_features))	# 用户输入
vu = user_NN(input_user)										# 用户神经网络的输出vu
vu = tf.linalg.l2_normalize (vu, axis=1)						# 正则化

# 创建项目输入并指向基本网络
input_item = tf.keras.layers.Input(shape=(num_item_features))	# 项目输入
vm = item_NN(input_item)										# 项目神经网络的输出vm
vm = tf.linalg.l2_normalize (vm, axis=1)						# 正则化

# 测量两个矢量输出的相似度
output = tf.keras.layers.Dot(axes=1)([vu,vm])					# 点乘两个神经网络输出

# 指定模型的输入和输出
model = Model([input_user, input_item], output)

# 指定成本函数
cost_fn = tf.keras.losses.MeanSquaredError()					# 平方误差成本函数

```



## 推荐系统补充

### 从大型目录中推荐（Recommending from a large catalogue）

比如：

- 电影，可能有上千部可供推荐
- 广告，可能有上百万的广告可推荐
- 歌曲，可能有上千万首歌可以推荐
- 商品，可能有上千种商品可以推荐



两个步骤：检索和排名

检索：

- 生成大量合理的项作为候选列表

  例如：

  - 在用户观看的最近10部电影中，每部都找到10部最相似的电影
  - 对于观看最多的3种类型的电影，每种类型找到排前10位的电影
  - 全国前20名的电影

- 将检索到的项目合并到列表中，删除已经看过/已经购买的项和重复项

排名：

- 使用学习模型获取检索到的列表和排序
- 将排序项显示给用户



检索步骤

- 检索更多的条目可以获得更好的性能，但推荐速度更慢
- 为了分析/优化交易，进行离线实验，看看检索额外的项目是否会获得更多的相关奖励
  （即，向用户显示的$p(y^{(i,j)})=1$的项目更多）



### 推荐系统中的伦理（Ethical use of recommender systems）

推荐制度的目标是什么？

推荐：

- 最有可能被用户评为五星级的电影
- 最有可能购买的产品
- 最有可能被点击的广告
- 产生最大利润的产品
- 导致最大观看时间的视频



这里面可能会有一些伦理问题

例如：

- 贷款业，推荐系统可能会帮助从用户那里进行剥削

  改进：不接受剥削性企业的广告。但这往往是比较难定义的问题

- 用户参与最大化（如观看时间）已导致大型社交媒体/视频分享网站  放大阴谋论和仇恨/毒性

  改进：过滤掉有问题的内容，如仇恨言论、欺诈、诈骗和暴力内容。

- 一个排名系统能以透明的方式来实现你的利润最大化而不是用户的福利吗？

  改进：对用户透明

























