# 吴恩达深度学习

# 目录

# 优化算法

小笔记（群里讨论时记的）：优化么，洗数据，特征工程，bad case分析，换更大模型，增强模型内参数传播

## 小批量梯度下降（Mini-batch gradient descent）

### Mini-batch 梯度下降

向量化超大样本 的缺点

> 之前学过，向量化能够让你有效地对所有$m$个样本进行计算，我们要把训练样本放大巨大的矩阵当中：
> $X= \lbrack x^{(1)}\ x^{(2)}\ x^{(3)}\ldots\ldots x^{(m)}\rbrack$，$X$的维数是$(n_{x},m)$，
> $Y= \lbrack y^{(1)}\ y^{(2)}\ y^{(3)}\ldots \ldots y^{(m)}\rbrack$，$Y$的维数是$(1,m)$，
> 向量化能够让你相对较快地处理所有$m$个样本。但如果$m$很大的话，处理速度仍然**缓慢**



原理

> 如果$m$是500万或5000万或者更大的一个数，在对整个训练集执行梯度下降法时。
> 你必须处理整个训练集的500万个训练样本，进行一步梯度下降法，然后要再重新处理500万个训练样本，进行下一步梯度下降法。
> 如果你在处理完整个500万个样本的训练集之前，先让梯度下降法处理一部分，你的算法速度会更快，这就是Mini-batch梯度下降的思想



新的术语

> mini-batch：
>
> 把训练集分割为小一点的子集训练，这些子集被取名为**mini-batch**。
> 假设每一个子集中只有1000个样本，那么把其中的$x^{(1)}$到$x^{(1000)}$取出来，将其称为第一个子训练集，也叫做mini-batch，
> 然后你再取出接下来的1000个样本，从$x^{(1001)}$到$x^{(2000)}$，然后再取1000个样本，以此类推。
>
> 
>
> 大括号 { }：
>
> 接下来我要说一个新的符号，把$x^{(1)}$到$x^{(1000)}$称为$X^{\{1\}}$，$x^{(1001)}$到$x^{(2000)}$称为$X^{\{2\}}$，
> 如果你的训练样本一共有500万个，每个mini-batch都有1000个样本，那么共有5000个mini-batch，最后得到是$X^{\left\{ 5000 \right\}}$。对$Y$也要进行相同处理
>
> 
>
> $X^{\{ t\}}$和$Y^{\{ t\}}$的维数：
> 如果$X^{\{1\}}$是一个有1000个样本的训练集，所有的子集$X^{\{ t\}}$维数都是$(n_{x},1000)$，$Y^{\{ t\}}$的维数都是$(1,1000)$
>
> 
>
> 一代：
>
> 遍历完整个$(X,Y)$，也可被称为进行 **“一代”**（**1 epoch**）的训练。一代这个词意味着只是一次遍历了训练集。



结合正则化

> 如果你用到了正则化。这是普通梯度下降法的正则化：
>
> $J =\frac{1}{1000}\sum_{i = 1}^{l}{L(\hat y^{(i)},y^{(i)})} +\frac{\lambda}{2 1000}\sum_{l}^{}{||w^{[l]}||}_{F}^{2}$
>
> 这是mini-batch梯度下降法中的表示：
>
> $J^{\{t\}} = \frac{1}{1000}\sum_{i = 1}^{l}{L(\hat y^{(i)},y^{(i)})} +\frac{\lambda}{2 1000}\sum_{l}^{}{||w^{[l]}||}_{F}^{2}$



比较

> 名称
>
> - **batch**梯度下降法：
>
>   指的是我们之前讲过的梯度下降法算法，同时处理整个训练集。
>   这个名字就是来源于能够同时看到整个batch训练集的样本被处理，这个名字不怎么样，但就是这样叫它。
>
> - **mini-batch**梯度下降法：
>
>   每次同时处理的单个的mini-batch $X^{\{t\}}$和$Y^{\{ t\}}$，而不是同时处理全部的$X$和$Y$训练集。
>
> 速度
>
> - batch梯度下降法：
>
>   一次遍历训练集只能让你做一个梯度下降
>
> - mini-batch梯度下降法：
>
>   一次遍历训练集，能让你做5000个梯度下降（5000=500万/1000）
>   当然如果你想要多次遍历训练集，还需要为另一个while循环设置另一个for循环。所以你可以一直处理遍历训练集，直到最后你能收敛到一个合适的精度
>
> 一些补充：
>
> 如果你有一个非常大的训练集，mini-batch梯度下降法比batch梯度下降法运行地更快。几乎每个研习深度学习的人在训练巨大的数据集时都会用到



### 理解mini-batch梯度下降法（Understanding mini-batch gradient descent）

看下面的三种情况：

- 极端情况 - mini-batch的大小等于$m$，其实就是**batch梯度下降法**
- 极端情况 - mini-batch的大小等于1，该新的算法叫**随机梯度下降法**。每个样本都是独立的mini-batch
- 正常情况 - mini-batch的大小适中，即为正常的**min-batch梯度下降法**

![](02. 优化算法.assets/bb2398f985f57c5d422df3c71437e5ea.png)

（图中：蓝线为batch梯度下降法、紫线为随机梯度下降法，绿线为min-batch梯度下降法）



分析：

- batch梯度下降法：噪声低，步进幅度大，可以收敛

- 随机梯度下降法：噪声很大，需要更小的学习率降噪。

  - 缺点1：它最终会靠近最小值，不过有时候也会方向错误。并且永远不会收敛，而是会一直在最小值附近波动
  - 缺点2：失去了向量化的加速

- mini-batch下降法：mini-batch大小应该1和m之间

  大小较大时，下降速度越快，但产生的噪声越多。没有每次迭代都下降是不要紧的，但走势应该向下

  它比随机梯度下降要更持续地靠近最小值的方向，但它也不一定在很小的范围内收敛或者波动。解决方法是结合**学习率衰减**使用



mini-batch大小的选择

- 如果训练集较小，直接使用batch梯度下降法
  - 这里的少是说小于2000个样本，必要使用mini-batch梯度下降法
- 样本数目较大的话，一般的mini-batch大小为64到512
  - 考虑到电脑内存设置和使用的方式，如果mini-batch大小是2的$n$次方，代码会运行地快一些。一般是64~512，也有1024但比较少见
- （这条我没懂）最后需要注意mini-batch中，要确保$X^{\{ t\}}$和$Y^{\{t\}}$要符合**CPU**/**GPU**内存，取决于你的应用方向以及训练集的大小
- 多尝试几个值，试图找到一个高效的方案



mini-batch梯度下降，令算法运行得更快，特别是在训练样本数目较大的情况下。
不过**还有个更高效的算法**，比梯度下降法和mini-batch梯度下降法都要高效的多，后面再讲解。（看目录应该是 “动量梯度下降法”）

## Momentum（动量梯度下降法）

~~原标题：动量梯度下降法（Gradient descent with Momentum）~~



### 【前置知识】指数加权平均数（Exponentially weighted averages）

我想向你展示几个优化算法，它们比梯度下降法快，
但要理解这些算法，你需要用到**指数加权平均**，在统计中也叫做**指数加权移动平均**，我们首先讲这个，然后再来讲更复杂的优化算法。



它在统计学中被称为**指数加权移动平均值**，我们就简称为**指数加权平均数**（好像有时你也会简称为**移动平均值**）

- “**移动**” 可以理解为使用了该算法后曲线会右移。当$\beta$参数进一步增大、平均更多的天数时，右移程度会更大
- “**平均**” 可以理解为该算法降噪了，有点像将几天（$\frac{1}{(1 -\beta)}$）平均成一天来看的感觉
- “**指数**” 应该指的是将迭代式全部展开的式子，比如第一天的数据会一直影响后面的数据到最后一天（当然影响会越来越小）
- “**加权**” 这个简单，不解释



> #### 数据图

下图是一年的 天气-温度 图，起始于1月份，结束于12月末

![](02. 优化算法.assets/d49c52a460376e00c8e5b40baed2cf23.png)



> #### 指数加权平均值

操作：
$$
先令v_{0} =0\\
v_{t} = 0.9v_{t - 1} +0.1\theta_{t}\\~\\

通俗理解就是：\\
每天用0.9加权之前的数值加上当日温度的0.1倍，\\
某天的v等于前一天v值的0.9加上当日温度的0.1\\~\\

我们把0.9这个常数变成\beta，将之前的0.1变成(1 - \beta)\\
v_{t} = \beta v_{t - 1} + (1 - \beta)\theta_{t}
$$


举例：

- 第一天：$v_{1} =0.9v_{0} + 0.1\theta_{1}$，所以这里是第一天的温度值。
- 第二天：$v_{2}= 0.9v_{1} + 0.1\theta_{2}$，以此类推。
- 第三天：$v_3=0.9v_2+0.1\theta_3$，如此往下。

代码表示：

```python
v = 0
for i:
    get theta_t
    v = beta*v + (1-beta)*theta_t
```



图像：

如此计算，用红线作图的话，得到下图：

![](02. 优化算法.assets/4324e926e3ba304e339cda820f61fc28.png)



平均温度：

在计算时可视$v_{t}$大概是$\frac{1}{(1 -\beta)}$的每日温度。

如果$\beta$是0.9，这是十天的平均值，也就是红线

将$\beta$设置为接近1的一个值，比如0.98，计算$\frac{1}{(1 - 0.98)} =50$，也就是绿线的部分



> #### $\beta$的选值

| $\beta$的值  | 线色 | 图像                                                         | 平均几天 |
| ------------ | ---- | ------------------------------------------------------------ | -------- |
| $\beta=0.9$  | 红线 | ![](02. 优化算法.assets/4324e926e3ba304e339cda820f61fc28.png) | 10天     |
| $\beta=0.95$ | 绿线 | ![](02. 优化算法.assets/a3b26bbce9cd3d0decba5aa8b26af035.png) | 50天     |
| $\beta=0.5$  | 黄线 | ![](02. 优化算法.assets/369ae78c3b63e5b537cc0e30f60eb471.png) | 2天      |



- $\beta$较大时

  - 比如$\beta=0.98$
  - 优点：曲线波动更小，更加平坦。原因在于你多平均了几天的温度

  - 缺点：曲线进一步**右移**。指数加权平均公式在温度变化时，适应地更缓慢一些，所以会出现一定**延迟**

- $\beta$较小时

  - 比如$\beta=0.5$

  - 缺点：平均的数据太少，曲线有更多的噪声，有可能出现异常值
  - 优点：这个曲线能够更快适应温度变化

- 选用

  - 通过调整$\beta$参数，或者说后面的算法学习，你会发现这是一个很重要的参数，可以取得稍微不同的效果。
    往往中间有某个值效果最好，$\beta$为中间值时得到的红色曲线，比起绿线和黄线更好地平均了温度。



### 【前置知识】指数加权平均数 - 深入理解

指数加权平均数的关键方程：${{v}_{t}}=\beta {{v}_{t-1}}+(1-\beta ){{\theta }_{t}}$

$\beta=0.90$时，结果是红线，
$\beta=0.98$时，结果是绿线，
$\beta=0.50$时，结果是黄线。

![](02. 优化算法.assets/369ae78c3b63e5b537cc0e30f60eb471.png)



每日温度的平均值：

我们进一步地分析，来理解如何计算出每日温度的平均值。

$t$从0到1到2到3，$t$的值在不断增加。但为了更好地分析，反过来写，使$t$的值不断减小

$$
v_{100}=0.9v_{99}+0.1\theta_{100}\\
v_{99}=0.9v_{98}+0.1\theta_{99}\\
v_{98}=0.9v_{97}+0.1\theta_{98}\\
\cdots
$$
以此类推，如果你把这些括号都展开：
$$
\begin{align}
    v_{100} =&~ 0.1\theta_{100} + 0.1 \times 0.9 \theta_{99} + 0.1 \times {(0.9)}^{2}\theta_{98} + 0.1 \times {(0.9)}^{3}\theta_{97} + 0.1 \times {(0.9)}^{4}\theta_{96} + \ldots\\
    
    =&~ 0.1 \times \theta_{100} \\
    +&~ 0.1 \times 0.9~ \theta_{99} \\
    +&~ 0.1 \times {(0.9)}^{2}\theta_{98} \\
    +&~ 0.1 \times {(0.9)}^{3}\theta_{97} \\
    +&~ 0.1 \times {(0.9)}^{4}\theta_{96} \\
    +&~ \ldots
\end{align}
$$
这些系数（$0.1,~0.1 \times 0.9,~0.1 \times {(0.9)}^{2},~0.1 \times {(0.9)}^{3}\ldots$），**相加起来为1或者逼近1**，我们称之为**偏差修正**，下一节会涉及



到底需要平均多少天的温度？==（这里我不是很懂，平均温度用来干嘛，为什么需要计算平均温度？）==
$$
{(1-\varepsilon)}^{(\frac{1}{\varepsilon})}\\~\\

\begin{align}
    当\varepsilon=0.10时：&
    原式=0.90^{10}\approx 0.3487\approx\frac{1}{e}\approx 0.3679\\

    当\varepsilon=0.02时：&
    原式=0.98^{50}\approx 0.3642\approx\frac{1}{e}\approx 0.3679\\

    当\varepsilon=0.0001时：&
    原式=0.9999^{0.0001}\approx 0.3679\approx\frac{1}{e}\approx 0.3679\\
\end{align}\\~\\

这其实是数学里的一个极限：\lim_{x\rightarrow\infty}(1+\frac 1x)^x=\frac 1e
$$
我们由此得到公式，我们平均了大约$\frac{1}{(1-\beta)}$​天的温度（这里$1-\beta$​代替了$\varepsilon$​）
也就是说根据一些常数，你能**大概**知道能够平均多少日的温度，不过这只是思考的大致方向，并不是正式的数学证明。



指数加权平均数公式

- 优点
  - 占用极少内存，电脑内存中只占用一行数字而已，基本上只占用一行代码，然后把最新数据代入公式，不断覆盖就可以了
- 缺点
  - 如果保存所有最近的温度数据，和过去10天的总和，必须占用更多的内存，执行更加复杂，计算成本也更加高昂
  - 当然它并不是最好的，也不是最精准的计算平均数的方法。下一节会使用**偏差修正**计算更准确的计算方式



### 【前置知识】指数加权平均数 - 偏差修正（Bias correction）

有一个技术名词叫做**偏差修正**，可以让**平均数运算更加准确**



${{v}_{t}}=\beta {{v}_{t-1}}+(1-\beta ){{\theta }_{t}}$

![](02. 优化算法.assets/26a3c3022a7f7ae7ba0cd27fc74cbcf6.png)

- $\beta=0.90$时对应**红色**曲线，
- $\beta=0.98$时理想对应**绿色**曲线，
- $\beta=0.98$时实际对应**紫色**曲线。紫色曲线相比绿色的起点更低，我们来看看怎么处理

原因：

- 计算第一天时

  $v_{0} = 0$，$v_{1} = 0.02$，$v_{1} = 0.98v_{0} +0.02\theta_{1}=0.02\theta_1$

  若$\theta_1=40$，$原式=0.02\times40=0.8$。得到的值会小很多，所以第一天温度的估测不准。

- 计算第二天时

  $v_{2} = 0.98v_{1} + 0.02\theta_{2}= 0.98 \times 0.02\theta_{1} + 0.02\theta_{2} = 0.0196\theta_{1} +0.02\theta_{2}$

  假设$\theta_{1}$和$\theta_{2}$都是正数，计算后$v_{2}$要远小于$\theta_{1}$和$\theta_{2}$，所以$v_{2}$不能很好估测出这一年前两天的温度。

解决方法：

- 有个办法可以修改这一估测，让估测变得更好，更准确，特别是在估测初期，也就是不用$v_{t}$​，而是用$\frac{v_{t}}{1- \beta^{t}}$​，t就是现在的天数。
  $$
  ~\begin{align}
      原公式： {{v}_{t原}}=&\beta {{v}_{t-1}}+(1-\beta ){{\theta }_{t}}\\
      带偏差修正的公式： {{v}_{t新}}
      =&\frac{{v}_{t原}}{1-\beta^t}\\
      =&\frac{\beta {{v}_{t-1}}+(1-\beta ){{\theta }_{t}}}{1-\beta^t}\\
      =&\frac\beta{1-\beta^t}v^{t-1}+\frac{(1-\beta)}{1-\beta^t}\theta_t
  \end{align}\\~\\
  其中，分母(1-\beta^t)取值(0,1)
  $$

举例：

- 估测第二天温度
  $$
  原公式，估测值比实际温度低很多：\\
  v_{2}  = 0.0196\theta_{1} +0.02\theta_{2}\\~\\
  
  带偏差修正的公式，估测值和实际温度差不多：\\
  1 - \beta^{t} = 1 -  {0.98}^{2} = 0.0396\\
  
  v2:=\frac{v_{2}}{0.0396} = 0.4950\theta_1+0.5051\theta_2
  $$

- **在后续学习阶段**，$t$很大时$\beta^{t}$接近于0，偏差修正几乎没有作用，紫线基本和绿线重合了

- **在开始学习阶段**，偏差修正可以帮助你更好预测温度，可以帮助你使结果从紫线变成绿线



其他补充

在计算指数加权平均数的大部分时候，大家不在乎执行偏差修正，因为大部分人宁愿熬过初始时期，拿到具有偏差的估测，然后继续计算下去。
如果你关心初始时期的偏差，在刚开始计算指数加权移动平均数的时候，偏差修正能帮助你在早期获取更好的估测。

所以你学会了计算指数加权移动平均数，我们接着用它来构建更好的优化算法吧！



### 动量梯度下降法

还有一种算法叫做**Momentum**，或者叫做**动量梯度下降法**。运行速度几乎总是**快于标准的梯度下降算法**。



简而言之，基本的想法就是计算梯度的指数加权平均数，并利用该梯度更新你的权重

例如，如果你要优化成本函数，函数形状如图，红点代表最小值的位置，假设你从这里（蓝色点）开始梯度下降法，如果进行梯度下降法的一次迭代，无论是batch或mini-batch下降法，也许会指向这里，现在在椭圆的另一边，计算下一步梯度下降，结果或许如此，然后再计算一步，再一步，计算下去，你会发现梯度下降法要很多计算步骤对吧？



这种**上下波动减慢了梯度下降法的速度，你就无法使用更大的学习率**，如果你要用较大的学习率（紫色箭头），结果可能会偏离函数的范围

![](02. 优化算法.assets/cc2d415b8ccda9fdaba12c575d4d3c4b.png)

在纵轴上，你希望学习慢一点，因为你不想要这些摆动。
在横轴上，你希望加快学习，你希望快速从左向右移，移向最小值，移向红点。



动量梯度下降法
$$
之前计算移动平均数的公式：\\
v = \beta v + \left( 1 - \beta \right)\theta_{t}\\~\\

类似的，我们可以在梯度下降时进行降噪：\\
\begin{align}
v_{dW}=& \beta v_{dW} + \left( 1 - \beta \right)dW\\
v_{db} =& \beta v_{db} + ( 1 - \beta){db}\\~\\


W:=& W  -a\cdot v_{dW}\\
b:=& b~~-a\cdot v_{db}
\end{align}
$$
补充

> $v_{{dW}}$初始值是0，和$dW$拥有相同维数的零矩阵，也就是跟$W$拥有相同的维数。
> $v_{db}$初始值也是向量零，和$db$拥有相同的维数，也就是和$b$是同一维数。
>
> 在梯度下降中不需要考虑偏差修正



一些理解思路

- 降噪理解：

  指数加权平均数，能起到类似于降噪整流的功能。而用在梯度下降中，能降低梯度下降方向的噪点，使下降方向更平滑
  算法走了一条更加直接的路径，在抵达最小值的路上减少了摆动

- 球的滚动：

  想象你有一个碗，你拿一个球，微分项给了这个球一个加速度，此时球正向山下滚，球因为加速度越滚越快，而因为$\beta$ 稍小于1，表现出一些摩擦力，所以球不会无限加速下去，所以不像梯度下降法，每一步都独立于之前的步骤，你的球可以向下滚，获得动量，可以从碗向下加速获得动量。



两个超参数

- 所以你有两个超参数，学习率$a$以及参数$\beta$

- $\beta$控制着指数加权平均数。$\beta$**最常用的值是0.9**

  我们之前平均了过去十天的温度，所以现在平均了前十次迭代的梯度。你可以尝试不同的值，可以做一些超参数的研究，不过0.9是很棒的鲁棒数。

- **不需要考虑偏差修正**。你可以拿$v_{dW}$和$v_{db}$除以$1-\beta^{t}$，但实际上人们不这么做

  因为10次迭代之后，因为你的移动平均已经过了初始阶段。实际中使用梯度下降法或动量梯度下降法时，人们不会受到偏差修正的困扰



公式的第二种写法

> 最后要说一点，如果你查阅了动量梯度下降法相关资料，你经常会看到不是$v_{dW}= \beta v_{{dW}} +{\color{red}(1-\beta)}dW$而是$v_{dW}= \beta v_{{dW}} +dW$
>
> 这两种写法都可以。但使用第二种写法时，$v_{{dW}}$缩小了$1-\beta$倍，所以你要用梯度下降最新值的话，$a$要根据$\frac{1}{1 -\beta}$相应变化
>
> > 我（“我” 指吴恩达老师）认为第二种用起来没有那么自然，因为如果你要调整超参数$\beta$，就会影响到$v_{{dW}}$和$v_{db}$，你也许还要修改学习率$a$。
> > 所以我更喜欢第一种的公式。
> >
> > 但是两个公式都将$\beta$设置为0.9，是超参数的常见选择，只是在这两个公式中，学习率$a$的调整会有所不同。



## RMSprop（均方根传递，Root Mean Square prop）

一些英语：

- 动量（Momentum）
- 均方根、平方平均数（Root Mean Square），Root根  Mean平均  Square平方
- 均方根Prop（RMSprop，Root Mean Square prop），prop暂时不知道怎么翻译
- 均方根误差（Root Mean Square error）



动量（Momentum）可以加快梯度下降，还有一个叫做**RMSprop**（**root mean square prop**）的算法，也可以加速梯度下降

算法的名字：**RMSprop**，全称是**均方根Prop** 。因为你将微分进行平方，然后最后使用平方根。



作用：

> 我们之前的例子执行梯度下降时，虽然横轴方向正在推进，但纵轴方向会有大幅度摆动。
> 假设纵轴代表参数$b$，横轴代表参数$W$
>
> ![](02. 优化算法.assets/553ee26f6efd82d9996dec5f77e3f12e.png)
>
> 你如果希望减缓$b$方向（即纵轴方向）的学习，同时加快，至少不是减缓横轴方向的学习。**RMSprop**算法可以实现这一点（蓝线变绿线）
>
> 纵轴方向上摆动较小，而横轴方向继续推进。还有个影响就是，你可以用一个更大学习率$a$，然后加快学习。
>
> 
>
> - Q：为什么W能表示横轴，b能表示纵轴？
>
> - A：看上图中的碗 (凸) 函数的俯视图就知道了。
>
>   另外要说明一点，把纵轴和横轴方向分别称为$b$和$W$，只是为了方便展示而已。实际中可能会有更高维度的空间
>
>   例如，垂直维度的摆动可能是参数$W_1,W_2$等的合集。水平维度则可能$W_3,W_4$等
>   



实现：

旧方案（普通的梯度下降法）
$$
\begin{align}
    W:=& W  -a\cdot dW\\
    b:=& b~~-a\cdot db
\end{align}
$$
旧方案（动量梯度下降法）
$$
\begin{align}
    v_{dW}=& \beta v_{dW} + \left( 1 - \beta \right)dW\\
    v_{db} =& \beta v_{db} + ( 1 - \beta){db}\\~\\


    W:=& W  -a\cdot v_{dW}\\
    b:=& b~~-a\cdot v_{db}
\end{align}
$$
新方案（RMSprop）

我们用到**新符号**$S_{dW},S_{db}$，而不是$v_{dW},v_{db}$。公式上也多一个平方
$$
~
\begin{align}
    S_{dW}=& \beta_2 S_{dW}   + (1 -\beta_2) {dW}^{\color{red}2}\\
    S_{db}=& \beta_2 S_{db} ~~+ (1 -\beta_2) {db}^{\color{red}2}\\~\\
    
    W:=& W  -a\cdot \frac{dw}{\sqrt{S_{dW}}}\\
	b:=& b~~-a\cdot \frac{db}{\sqrt{S_{db}}}
\end{align}\\~\\

{\color{red}注意这个平方的操作}是针对这一整个符号的操作，这样做能够保留微分平方的加权平均数\\
即dW^2=(dW)^2\neq d(W^2)
$$
补充：
下一节中，我们会将**RMSprop**和**Momentum**结合起来。
我们在Momentum中采用了超参数$\beta$，为了避免混淆，RMSprop中改用超参数$\beta_{2}$表示



原理：

> 在横轴方向 (例子中的$W$方向) ，我们希望学习速度快，
> 在垂直方向 (例子中的$b~~$方向) ，我们希望减缓纵轴上的摆动。所以有了$S_{dW}$和$S_{db}$。
>
> 因为$dW$较小，所以$S_{dW}$相对较小，最终$W$方向的更新会较大，
> 因为$db~~$较小，所以$S_{db}~~$相对较大，最终$b~~$方向的更新会较小。
>
> 在你要消除摆动的维度中，最终你要计算一个更大的和值，这个平方和微分的加权平均值，所以你最后去掉了那些有摆动的方向。



注意项：

> 要确保你的算法不会除以0，如果$S_{dW}$的平方根趋近于0，得到的答案就非常大，不利于确保数值的稳定
>
> 解决方案：实际操练时，在分母上加上一个很小很小的$\varepsilon$。$\varepsilon$是多少没关系，$10^{-8}$是个不错的选择，这只是保证数值能稳定一些，无论什么原因，你都不会除以一个很小很小的数。



小故事：

> 关于**RMSprop**的一个有趣的事是，它首次提出并不是在学术研究论文中，而是在多年前**Jeff Hinton**在**Coursera**的课程上。
> 我想**Coursera**并不是故意打算成为一个传播新兴的学术研究的平台，但是却达到了意想不到的效果。就是从**Coursera**课程开始，**RMSprop**开始被人们广为熟知，并且快速发展。



## Adam 优化算法（Adam optimization algorithm）

算法的名字：

- Q：为什么这个算法叫做Adam？

- A：**Adam**代表的是**Adaptive Moment Estimation**（自适应矩估计）
  $\beta_{1}$用于计算这个微分（$dW$），叫做第一矩，
  $\beta_{2}$用来计算平方数的指数加权平均数（${(dW)}^{2}$），叫做第二矩。
  所以Adam的名字由此而来，但是大家都简称Adam权威算法。

  （另外可能会有的人就叫Adam，但那与人名无关）



优点：

很多优化算法被指出不能一般化，而RMSprop以及Adam优化算法是少有的经受住人们考验的两种算法，已被证明适用于不同的深度学习结构

**Adam**优化算法基本上就是结合了**Momentum**和**RMSprop**梯度下降法。一种极其常用的学习算法，被证明能有效适用于不同神经网络，适用于广泛的结构



使用：
$$
Adam算法初始化：\\
\begin{aligned}
    v_{dW  } = 0，S_{dW  } =0\\
    v_{db~~} = 0，S_{db~~} =0
\end{aligned}\\注意计算dW,db时可以结合mini-batch计算\\~\\---------------------\\


\text{Momentum}法的~~指数加权平均数：\\
\begin{aligned}
    v_{dW  }=& \beta_{1}v_{dW  } + ( 1 -\beta_{1})dW  \\
    v_{db~~}=& \beta_{1}v_{db~~} + ( 1 -\beta_{1})db~~
\end{aligned}\\~\\---------------------\\


\text{RMSprop}法的~~参数：\\
\begin{aligned}
    S_{dW  }=& \beta_{2}S_{dW  } + ( 1 - \beta_{2}){(dW  )}^{2}\\
    S_{db~~}=& \beta_{2}S_{db~~} + ( 1 - \beta_{2}){(db~~)}^{2}
\end{aligned}\\~\\---------------------\\


Adam算法的时候，还要计算偏差修正：\\
\begin{aligned}
    v_{dW}^{\text{corrected}} =& \frac{v_{dW}}{1 - \beta_{1}^{t}}\\
    v_{db}^{\text{corrected}} =& \frac{v_{db}}{1 - \beta_{1}^{t}}\\
    S_{dW}^{\text{corrected}} =& \frac{S_{dW}}{1 - \beta_{2}^{t}}\\
    S_{db}^{\text{corrected}} =& \frac{S_{db}}{1 - \beta_{2}^{t}}
\end{aligned}\\~\\---------------------\\

梯度下降：\\
\begin{aligned}
    W:=& W  - \alpha\cdot \frac{v_{dW}^{\text{corrected}}}{\sqrt{S_{dW}^{\text{corrected}}} +\varepsilon}\\
    b:=& b~~- \alpha\cdot \frac{v_{db}^{\text{corrected}}}{\sqrt{S_{db}^{\text{corrected}}} +\varepsilon}
\end{aligned}
$$


本算法中有很多超参数：

- $a$   (学习率)：很重要，也经常需要调试，你可以尝试一系列值，然后看哪个有效
- $\beta_{1}$ (第一矩)：常用的缺省值为$\color{red}0.9$。这是dW的移动平均数，也就是$dW$的加权平均数
- $\beta_{2}$ (第二矩)：Adam论文作者暨算法的发明者，推荐使用$\color{red}0.999$。这是在计算${(dW)}^{2}$以及${(db)}^{2}$的移动加权平均值
- $\varepsilon$：其设置其实没那么重要，Adam论文的作者建议$\varepsilon$为$\color{red}10^{-8}$。但你并不需要设置它，因为它并不会影响算法表现
- 在使用Adam的时候，人们往往使用缺省值即可，$\beta_{1}$，$\beta_{2}$和$\varepsilon$都是如此。
  我觉得没人会去调整$\varepsilon$，然后尝试不同的$a$值，看看哪个效果最好。
  你也可以调整$\beta_{1}$和$\beta_{2}$，但我认识的业内人士很少这么干。



## 学习率衰减（Learning rate decay）

加快学习算法的一个办法就是随时间慢慢减少学习率，我们将之称为**学习率衰减**



场景：

假设你要使用mini-batch梯度下降法，mini-batch数量不大，大概64或者128个样本，在迭代过程中会有噪音（蓝色线）。
下降朝向这里的最小值，最后在附近摆动，但是不会真正地收敛。因为你用的$a$是**固定值**。



解决思路：

慢慢减少学习率$a$。其本质在于，在学习初期，你能承受较大的步伐，但当开始收敛的时候，小一些的学习率能让你步伐小一些。

结果：蓝线会变成绿线

![](02. 优化算法.assets/095feaa609b0029d6abc5c74ef7b3b35.png)



解决方案实现：

你应该拆分成不同的mini-batch，第一次遍历训练集叫做第一代。第二次就是第二代，依此类推。如下设置学习率$a$
$$
~
\begin{aligned}
    a=& \frac{1}{1 + \text{decay-rate} * \text{epoch-num}}a_{0}\\
     =& \frac{1}{1 + 衰减率 * 代数}初始学习率
\end{aligned}\\~\\
其中，除了初始学习率a_0，\{衰减率\}是你需要调整的另一超参数
$$


例如：

如果$a_{0}$为0.2，衰减率**decay-rate**为1。

第一代$a = \frac{1}{1 + 1}a_{0} = 0.1$，第二代$a=0.067$，第三代$a=0.05$，第四代$a=0.04$，……

你的学习率呈递减趋势。如果你想用学习率衰减，要做的是要去尝试不同的值，包括超参数$a_{0}$和衰退率



其他学习率衰减公式：

- $a= \frac{1}{1 + \text{decay-rate} * \text{epoch-num}}a_{0}$，当前公式

- $a ={0.95}^{\text{epoch-num}} a_{0}$，**指数衰减**，学习率呈指数下降

- $a =\frac{k}{\sqrt{\text{epoch-num}}}a_{0}$

- $a =\frac{k}{\sqrt{t}}a_{0}$（$t$为mini-batch的数字）。

- 有时人们也会用一个**离散下降**（**discrete stair cease**）的学习率。

  也就是某个步骤有某个学习率，一会之后，学习率减少了一半，一会儿减少一半，一会儿又一半

- 人们有时候还会做一件事，**手动衰减**。

  如果你一次只训练一个模型，如果你要花上数小时或数天来训练，有些人的确会这么做。
  看看自己的模型训练，耗上数日，然后他们觉得，学习速率变慢了，我把$a$调小一点。时复一时，日复一日地手动调整$a$。
  只有模型数量小的时候有用，但有时候人们也会这么做。

现在你有了多个选择来控制学习率$a$。你可能会想，好多超参数，究竟我应该做哪一个选择。下一章，我们会讲到，**如何系统选择超参数**。



## 局部最优的问题（The problem of local optima）

在深度学习研究早期，人们总是担心优化算法会陷入糟糕的**局部最优**（**Local Optima**）中，
不过随着深度学习理论不断发展，我们对局部最优的理解也发生了改变。下面介绍一些解决方案



事实上，如果你要创建一个神经网络，通常**梯度为零**的点并不是这个图中的**局部最优点**，而是**鞍点**。

![](02. 优化算法.assets/1f7df04b804836fbcadcd258c0b55f74.png)



> - Q：为什么更可能是鞍点而不是局部最优点？
>
> - A：一个具有高维度空间的函数，如果梯度为0，那么在每个方向，它可能是凸函数，也可能是凹函数。
>
>   如果你在2万维空间中，那么想要得到局部最优，所有的2万个方向都需要是这样，但**发生的机率也许很小**，也许是$2^{-20000}$，
>
>   你更有可能遇到有些方向的曲线会这样向上弯曲，另一些方向曲线向下弯，而不是所有的都向上弯曲，
>
>   因此在高维度空间，你更可能碰到鞍点。就像下面的这种：
>
>   ![](02. 优化算法.assets/c5e480c51363d55e8d5e43df1eee679b.png)
>
>   所以我们从深度学习历史中学到的一点就是：我们对低维度空间的大部分直觉，比如你可以画出二维或三维的图，并不能应用到高维度空间中
>
>   因为如果你有2万个参数，那么$J$函数有2万个维度向量，你更可能遇到鞍点，而不是局部最优点。



> - Q：为什么叫做鞍点？
> - A：因为长得就是放在马背上的马鞍一样。比如双曲抛物面也叫马鞍面



> - Q：如果局部最优不是问题，那么问题是什么？
>
> - A：问题是平稳段 (停滞区) 会减缓学习，平稳段是一块区域，其中导数长时间接近于0。
>
>   比如下图中：
>
>   ![](02. 优化算法.assets/607bd30801c87ed74bb95c49f218f632.png)
>
>   首先梯度会从曲面从从上向下下降，因为梯度等于或接近0，你得花上很长时间慢慢抵达鞍点。
>   然后因为左边或右边的随机扰动，然后你的算法能够走出平稳段（红色笔)



总结要点：

> - 首先，你不太可能困在极差的局部最优中（前提是你在训练较大的神经网络，存在大量参数，并且成本函数$J$被定义在较高的维度空间）
> - 其次，平稳段是一个问题，这样使得学习十分缓慢。
>   像**Momentum**、**RMSprop**、**Adam**这样的算法，能够加快学习速度，让你尽早往下走出平稳段。











