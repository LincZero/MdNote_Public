# 实战、个人环境备注

## LLM模型替换问题

### 换用更大参数量的模型

他这里默认是6b，可以给7G的显卡用。但公司电脑是24G显存的3090Ti，可以换用更强的本地模型。
这里大概算一下，b就是billion 十亿。 $7G=7*10^{3*3}=7B$，由于其他损耗就大概是7G显卡的样子。
但这也不一定，像 https://zhuanlan.zhihu.com/p/618690572 这里说这个130B缩放特性可以量化到100B级别，然后可以由 4x24G 来运行

参考：

- GPT-3 175B
- OPT-175B
- BLOOM-176B

### 同参数量的模型、量化or高参数量

另外，参数量相同的模型也会有差异。如新的优化方案导致性能不同，或者训练集不同，调参差异，导致的侧重点不同。以及双语的支持等，都是要考虑的重点。

参考：[中文羊驼大模型Alpaca-Plus-13B、Alpaca-33B效果大比拼](https://blog.csdn.net/nlpstarter/article/details/131129240)

模型比较

- Alpaca-Plus-13B：120G预训练，400万指令精调。
  - 特点：高训练数据，Q8量化
- Alpaca-33B：20G预训练，400万指令精调
  - 特点：模型量级大，Q4量化

测试

- 温室效应问题：33B的回答比较简练，内容长度上不占优
- 数学问题：骑7个猴。**33B的完胜**Plus-13B，可能模型量级对于这种数值计算和推理类的有较大优势吧
- 如何制作宫保鸡丁？：差不多
- 写一封信：Plus-13B占优一些，内容详实。可能33B吃了训练数据少的亏，写的内容不是特别生动
- 代码方面：**33B显著胜出**
- 角色扮演：差不多，13回复长，略优

总结

> Plus-13B相比之前的7B/13B已经有显著性能提升了，尤其是在生成类的任务上内容更加详实。33B的优缺点比较明显，优点是代码能力和数值计算方面确实比之前高出一截，但是在文本生成类的任务上效果略低于plus-13B。不过33B是基础版，这么比可能有点不讲武德，哈哈。这样其实就比较期待后续plus-33b的效果了，生成类任务的效果应该会有一个提升。

### 羊驼系模型

参考：

- [Guanaco, Llama, Vicuña, Alpaca该怎么区别](https://zhuanlan.zhihu.com/p/106262896)
- [大模型入门（一）—— LLaMa/Alpaca/Vicuna](https://www.cnblogs.com/jiangxinyang/p/17310398.html)
- https://blog.csdn.net/v_JULY_v/article/details/129709105

Vicuna是在LLaMa-13B的基础上使用监督数据微调得到的模型，数据集来自于ShareGPT.com 产生的用户对话数据，共70K条。使用Pytorch FSDP在8张A100上训练了一天。相较于Alpaca，Vicuna在训练中将序列长度由512扩展到了2048，并且通过梯度检测和flash  attention来解决内存问题；调整训练损失考虑多轮对话，并仅根据模型的输出进行微调。通过GPT4来打分评测，Vicuna可以达到ChatGPT 90%的效果。并且还提供了可调用的分布式聊天服务[FastChat](https://github.com/lm-sys/FastChat)。　　

一些模型图标的区分：https://kaiyuan.blog.csdn.net/article/details/131467606



















## bug1 无法找到显卡驱动

```bash
(base) root@msy-System-Product-Name:~# docker run -d --gpus all -p 80:8501 registry.cn-beijing.aliyuncs.com/chatchat/chatchat:0.2.0
4bcc140c4c5b24e21da7ba6bf863d372f899ddd20e141469959b08ac45b5cf5a
docker: Error response from daemon: could not select device driver "" with capabilities: [[gpu]].
```

解决该bug

---

这个错误通常发生在 Docker 无法在你的机器上找到正确的驱动程序来使用 GPU 的情况下。以下是一些可以解决这个问题的步骤：

1. **检查Docker版本是否支持 --gpus 选项**

   Docker从19.03版本开始支持原生使用GPU。用命令 `docker --version` 检查Docker版本，如果你使用的是更旧的版本，考虑更新Docker至最新版本。 

2. **检查是否安装了 NVIDIA 容器工具箱**

   如果你在docker中使用GPU，你需要安装nvidia-docker2，并在你的docker配置中添加NVIDIA运行时。如果没有安装，按照以下步骤进行安装 



a. **移除旧版本**

旧版本的 Docker 由名为 `nvidia-docker2` 的包支持。新的 Docker 版本由 NVIDIA 容器工具箱支持。如果你已经安装了旧的 `nvidia-docker2` 包，请移除它：

```bash
sudo apt-get purge -y nvidia-docker
```

b. **安装 NVIDIA 容器工具箱** - 添加包存储库：

```bash
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
sudo apt-get update
sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker
```

c. **测试 NVIDIA Docker 安装** - 通过运行一个示例来测试 NVIDIA Docker 的安装是否成功：

```bash
docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi
```



1. 如果仍然存在相同的错误，那么你应该检查Docker是否可以访问GPU。你可以通过运行命令 `nvidia-smi` 来检查。如果你可以看到你的GPU列表，Docker也应该能够使用它们。 
2. 确保您的机器上正确安装了 NVIDIA 驱动程序。您可以使用命令 `nvidia-smi` 来验证。 

如果问题仍然存在，请提供更多信息，以便我能更深入地帮助你。

## bug2 回答为空

群里另一个用 docker 方式的，也遇到了相同的问题。决定放弃docker方案，转手动部署。但我不想重新下这些模型包了，就在原docker的基础上重新部署吧

原

```bash
docker run -d --gpus all -p 80:8501 registry.cn-beijing.aliyuncs.com/chatchat/chatchat:0.2.0
```

现

```bash
# 可选，删掉旧的docker
docker stop xxx
dcker rm xxx

docker run -d --name=chatchat2 --restart=always -p 80:8501 f224e85162da

docker exec -it chatchat2 /bin/bash
```

## bug3 git问题

```bash
(base) root@msy-System-Product-Name:~/chatchat# git clone https://huggingface.co/moka-ai/m3e-base
正克隆到 'm3e-base'...
remote: Enumerating objects: 108, done.
remote: Counting objects: 100% (16/16), done.
remote: Compressing objects: 100% (15/15), done.
remote: Total 108 (delta 6), reused 0 (delta 0), pack-reused 92
接收对象中: 100% (108/108), 194.12 KiB | 2.55 MiB/s, 完成.
处理 delta 中: 100% (57/57), 完成.
```

git clone卡在这一步

尝试用安装 Git LFS 解决该问题。

在 Ubuntu 上安装 Git LFS 可以使用以下命令：

旧：

```bash
# 安装必要的软件包
$ sudo apt-get install git

# 下载并安装git-lfs
$ curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash
$ sudo apt-get install git-lfs

# 初始化git-lfs
$ git lfs install
```

新：

见官网链接

但看起来没成功

```bash
(base) root@msy-System-Product-Name:~/chatchat# git lfs install
Error: Failed to call git rev-parse --git-dir: exit status 128
Git LFS initialized.
```

后来直接复制黏贴了，不git了。其实就是10G的git时间太慢了而已。耐心等也可以，我选择先用有线下载再用wifi传过去

## bug4 找不到存在的路径

```bash
FileNotFoundError: [Errno 2] No usable temporary directory found in ['/tmp', '/var/tmp', '/usr/tmp', '/root/chatchat/Langchain-Chatchat']
```

但路径都是真实存在的

后来发现应该是我硬盘空间满了的原因

## bug5 一直卡在 wait controller running

分步运行中，用 ` python server/llm_api_stale.py` 则一直卡在wait controller running

换用回一键启动的命令，群友说那个分步启用的可能官方要不维护了

## bug6 爆显存

重启电脑解决





