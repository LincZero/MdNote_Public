# 李宏毅机器学习深度学习

笔记旧名：李宏毅2020机器学习深度学习

# 目录

# 学习准备

## 进度笔记

学习进度

- ==进度==：
  - p31 start
  - P58 ~ P59
- 跳过：
  - 重复的全部跳过
  - “选修” 全部跳过
- 笔记跳过：
  - 要配合github上的笔记使用，github笔记比较全，这门课其实很多笔记我都省略了
  - 优先看有pdf文件的，那部分是最重要的
  - 除了P03~04以外，基本都跳过
  - P58
- 链接：
  - 课程B站搬运地址（备用源，选一个即可）
    - 源1：https://www.bilibili.com/video/BV1Wv411h7kN（时长87:14:22，155p。
      啥都生他这个视频将21年和22年混在一起了，有的内容是重复的，章节混乱）
    - 源2：https://www.bilibili.com/video/BV1m3411p7wD（时长41:48:53，58p。2022纯享，无字幕差评。
      和下面的90p前58p内容一样，估计是没搬运完）
    - 源3：https://www.bilibili.com/video/BV1J94y1f7u5（时长54:15:55，90p。2022纯享，无字幕差评）
  - 2021课程原地址：https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.html
  - 2022课程原地址：https://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php
  - 课件和资料，github版：https://github.com/Fafa-DL/Lhy_Machine_Learning
  - 课件和资料，gitee版：https://gitee.com/zzhzwh/Lhy_Machine_Learning



## 课程资料

### 目录

==重新整理一遍阅读顺序==

- 主线：有pdf的章节，见后

- 零散的章节：P32
- P23接着是P33

2022课程大纲（一共十五讲）

| 2022课程   | 课程内容                                           | （主线）<br />对应视频 | 翻译、补充                                                   |
| ---------- | -------------------------------------------------- | ---------------------- | ------------------------------------------------------------ |
| Lecture 1  | Superviese Learning<br />监督式学习                | P3~4                   | 但是要手机一大堆有标记的数据                                 |
| Lecture 2  | 优化                                               | P18~22                 |                                                              |
| Lecture 3  | CNN<br />卷积神经网络                              | P31                    |                                                              |
| Lecture 4  | Self-attention<br />自注意力机制                   | P38~39                 |                                                              |
| Lecture 5  | Transformer                                        | P49~50                 |                                                              |
| Lecture 6  | Generative Adversarial Network<br />生成对抗的网络 |                        |                                                              |
| Lecture 7  | Self-supervised Learning<br />自监督学习           |                        | 先练基本功<br />Pre-train 训练 --> Downstream Tasks 下游任务 |
| Lecture 8  | Anomaly Detection<br />异常检测                    |                        | 回答 “I do not konw”                                         |
| Lecture 9  | Explainable AI<br />可辩解的人工智能               |                        | 不只是回答答案，还要告诉为什么<br />（如提取哪些特征点）     |
| Lecture 10 | Model Attack<br />模型的攻击                       |                        |                                                              |
| Lecture 11 | Domain Adaptation<br />领域适应                    |                        |                                                              |
| Lecture 12 | Reinforcement Learning (RL)<br />强化学习          |                        | 不知道怎么标注，但可以定义成功时用。例如棋类                 |
| Lecture 13 | Network Compression<br />网络压缩                  |                        |                                                              |
| Lecture 14 | Life-long Learning<br />终生学习                   |                        |                                                              |
| Lecture 15 | Meta Learning<br />元学习                          |                        | 让机器自己发明演算法<br />Few-shot learning 技术             |



2021课程大纲（一共十四讲）

| 2021课程 | 课程名                              | 作业                                              |
| -------- | ----------------------------------- | ------------------------------------------------- |
| 第一节   | Introduction                        | HW1: Regression                                   |
| 第二节   | Deep Learning                       | HW2: Classification                               |
| 第三节   | Self-Attention                      | HW3: Self-Attention                               |
| 第四节   | Theory of ML                        | ——                                                |
| 第五节   | Transformer                         | HW5: Transformer                                  |
| 第六节   | Generative Model                    | HW6: GAN                                          |
| 第七节   | Self-Supervised Learning            | HW7: BERT<br />HW8: Autoencoder                   |
| 第八节   | Explainable AI / Adversarial Attack | HW9: Explainable AI<br />HW10: Adversarial Attack |
| 第九节   | Domain Adaptation/ RL               | HW11: Adaptation                                  |
| 第十节   | RL                                  | HW12: RL                                          |
| 第十一节 | Privacy v.s. ML                     |                                                   |
| 第十二节 | Quantum ML                          |                                                   |
| 第十三节 | Life-Long/Compression               | 作业 HW13: Life-Long<br />HW14: Compression       |
| 第十四节 | Meta Learning                       | 作业 HW15: Meta Learning                          |



### PDF

1. 回归
2. 优化
   - 通用攻略
   - 局部最小值和鞍点（local minima & saddle point）
   - 批次与动量（batch & momentum）
   - 自动调整学习率（Learning Rate）
   - Batch归一化，损失函数（Loss）
3. CNN
4. 自注意力机制（Self-attention）
5. Transformer
6. GAN
7. 自监督学习，BERT（Bidirectional Enoceder Representations from Transformers，即双向Transformer的Encoder）
8. 自编码器（Auto-encoder）
9. 可解释AI（Explaninable AI）
10. **（没有PDF）**模型攻击（Adversarial Attack）
11. 概述领域自适应（Domain Adaptation）
12. 强化学习（Reinforcement Learning）
13. **（没有PDF）**神经网络压缩
14. **（没有PDF）**机器终身学习
15. **（没有PDF）**元学习



### 作业

- ① 确诊率的预测
- ② 风铃的classification，语音辨识的简化版
- ③ 影像辨识
- ④ -
- ⑤ 机器翻译
- ⑥ 动漫人脸的生成



## 机器学习基本概念

### 本质概念

- 是什么

  - 机器学习本质上是**让机器具备找一个函式的能力**

    比如声音变字、图像识别等，通过机器生成一个人类写不出来的函数

- 分类（根据输出类型/任务，有三大类）

  - Regression: 输出是一个数值

  - Classification：选择一个选项作为输出，例如训练棋类模型

  - Structured Learning：产生一个新的东西，例如ai文章和绘画





















