# 吴恩达机器学习

# 目录

# 多分类逻辑回归模型（Softmax）

## 概念

- 二元分类（Binary Classification）：只有两个分类
  - 例如判断是或不是的情况

- 多分类（Multiclass classification）：有多个分类
  - 例如手写体的数字识别（选择0~9）
  - 例如在一个图像中判断哪些是人哪些是小车哪些是汽车


## ① 定义模型、激活函数

### 二元分类逻辑回归

公式：
$$
\begin{align}
a_1=&g(z)=\frac 1{1+e^{-z}}&&=P(y=1|\vec x)\\
a_2=&1-a_1&&=P(y=0|\vec x)
\end{align}
$$

### 多分类逻辑回归（Softmax）

（Softmax 翻译 分类器，不一定正确）

通用公式：
$$
\begin{align}
z_j=&\vec w_j\cdot\vec x+b_j，~~~j=1,\cdots,N\\
a_j=&\frac{e^{z_j}}{\sum_{k=1}^{N}e^{z_k}}=P(y=j|\vec x)
\end{align}
$$
举例 - 设有四种分类：
$$
先定义四个逻辑回归公式：\\
z_1=\vec w_1\cdot \vec x+b_1\\
z_2=\vec w_2\cdot \vec x+b_2\\
z_3=\vec w_3\cdot \vec x+b_3\\
z_4=\vec w_4\cdot \vec x+b_4\\~\\

然后可求得四种概率分别：\\
\begin{align}
a_1=\frac{e^{z_1}}{e^{z_1}+e^{z_2}+e^{z_3}+e^{z_4}}=P(y=1|\vec x)\\
a_2=\frac{e^{z_2}}{e^{z_1}+e^{z_2}+e^{z_3}+e^{z_4}}=P(y=2|\vec x)\\
a_3=\frac{e^{z_3}}{e^{z_1}+e^{z_2}+e^{z_3}+e^{z_4}}=P(y=3|\vec x)\\
a_4=\frac{e^{z_4}}{e^{z_1}+e^{z_2}+e^{z_3}+e^{z_4}}=P(y=4|\vec x)\\
\end{align}\\
相加为1
$$

## ② Loss函数

### 二元分类逻辑回归

$y=0/1$

Loss函数：

$$
Loss=-y\log a_1-(1-y)\log(1-a_1)
$$

### 多分类逻辑回归（Softmax）

由于$y>0$

Loss函数：
$$
Loss(a_1,\cdots,a_N,y)=\
\begin{cases}
	-\log a_1 &&\text{if } y=1\\
	-\log a_2 &&\text{if } y=2\\
	~~~~\vdots && ~~~~\vdots\\
	-\log a_N &&\text{if } y=N\\
\end{cases}
$$

## ③ 神经网络的Softmax输出

### 区分：多类分类 & 多标签分类

先区分以下两个概念，不要混淆

- 多类分类（Multiiclass Classification）（Softmax输出？）
  - 像是之前的例子，例如手写体的数字识别（选择0~9），输出y
  - 输出：$\vec y=[P_1,P_2,\cdots,P_n]，\sum P=1$
- 多标签分类（Multi-label Classification）
  - 我们需要同时检测多个物品的多个类别，例如在一个图像中判断哪些是人哪些是小车哪些是巴士
    繁琐的做法是建立三个神经网络，分别是找小车、巴士、人。但一般来说，更好的做法是只训练一个模型，就能去分辨这三种东西
  - 输出：$\vec y=[P_1,P_2,\cdots,P_n]，\forall P\sub[0,1]$

### Softmax输出层

之前的神经网络的输出层都是只有一个单元，而多分类神经网络的输出层是Softmax输出，Softmax层也称Softmax激活函数，最后的输出是一个向量。

除了这个区别以外，其他的和之前的神经网络训练基本相同

### 一般写法

```python
"""
注意：代码仅供演示，不要抄，后面会学更好的处理方式
"""
import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense

# 1. 定义模型、定义层与激活函数
model = Sequential([		# 比如我们的两个隐藏层使用ReLU，最后的输出层使用Softmax
    Dense(units=25, activation='relu'),
    Dense(units=25, activation='relu'),
    Dense(units=10, activation='softmax'),
])

# 2. 定义Loss和Cost
from tensorflow.keras.losses import SparseCategoricalCrossentropy
model.compile(loss = SparseCategoricalCrossentropy())

# 3. 最优化、模型训练
model.fit(X,Y,epochs=100)

```









