# 吴恩达机器学习

# 目录

# 2022 机器学习 - 学习准备

## 进度笔记

学习进度

- ==进度==：全部看完，总共142P
- 跳过：
  - P56~P58 (6.2~6.4 矩阵乘法)
  - P81 看不懂

- 笔记：完全同步
  这个课系列的笔记我没有大幅度重新分章，因为有官方笔记，保留原来的章节结构方便两相照应，所以分类会有点乱
  
- 链接：https://www.bilibili.com/video/BV1Pa411X76s



## 资料文件夹结构

github：2022-Machine-Learning-Specialization-main

优点是官方笔记、缺点是英文笔记

有点乱，包含pdf ppt **ipynb**等，其中ipynb是最主要的参考



Machine learning specialization课程共分为三部分，每部分分为若干周，每周分为若干课。累计10周课

- ① 监督机器学习 - 回归与分类 *Supervised Machine Learning Regression and Classification*

  共3周

  - C1W1
  - C1W2
  - C1W3
- ② 高级学习算法 *Advanced Learning Algorithms*

  共4周

  - C2W1
  - C2W2
  - C2W3
  - C2W4
- ③ 无监督学习 - 推荐强化学习 *Unsupervised learning recommenders reinforcement learning*

  共3周

  - C3W1
  - C3W2
  - C3W3



其中 weekN 目录下包括

- ……（一些补充资料）
- slides（PPT文件）
- work（工作路径，**ipynb**文件）

## 课程目录

### 第一课

#### 第一周，单变量线性回归模型

- 1.1
  - 机器学习应用
- 1.2
  - 机器学习定义
  - 监督学习
  - 无监督学习
  - Juperter Notebooks
- 1.3
  - 线性回归模型
  - 代价函数公式
  - 理解代价函数
  - 可视化代价函数
  - 可视化举例
- 1.4
  - 梯度下降
  - 梯度下降的实现
  - 理解梯度下降
  - 学习率
  - 用于线性回归的梯度下降
  - 运行梯度下降

#### 第二周，多元线性回归模型

- 2.1
  - 多维特征
  - 向量化
  - 用于多元线性回归的梯度下降法
- 2.2
  - 特征缩放
  - 判断梯度下降
  - 如何设置学习率
  - 特征工程
  - 多项式回归

#### 第三周

- 3.1
  - 动机与目的
  - 逻辑回归
  - 决策边界
- 3.2
  - 逻辑回归中的代价函数
  - 简化逻辑回归代价函数
  - 实现梯度下降
  - 过拟合问题
  - 解决过拟合
  - 正则化
  - 用于线性回归的正则鲂
  - 用于逻辑回归的正则方法

### 第二课

#### 第一周

- 4.1
  - 欢迎
  - 神经元和大脑
  - 需求预测
  - 举例-图像感知
- 4.2
  - 神经网络中的网络层
  - 更复杂的神经网络
  - 神经网络前向传播
- 4.3
  - 如何用代码实现推理
  - Tensorflow中数据形式
  - 搭建一个神经网络
- 4.1
  - 单个网络层上的前向传播
  - 前向传播的一般实现
- 4.5
  - 强人工智能
- 4.6
  - 神经网络为何如此高效
  - 矩阵乘法
  - 矩阵乘法规则
  - 矩阵乘法代码

#### 第二周

- 5.1
  - Tensorflow实现
  - 模型训练细节
- 5.2
  - Sigmoid激活函数的替代方案
  - 如何选择激活函数
- 5.3
  - 多分类问题
  - Softmax
  - 神经网络的Softmax输出
  - Softmax的改进实现
  - 多个输出的分类
- 5.4
  - 高级优化方案
  - 其他的网络层类型
- …… 太多了不打了











#### 第三周

#### 第四周

### 第三课

#### 第一周

#### 第二周

#### 第三周



## 数学基础

### *数学矩阵基础（选修）*

#### 矩阵乘法

#### 矩阵乘法规则

#### 矩阵乘法代码

























